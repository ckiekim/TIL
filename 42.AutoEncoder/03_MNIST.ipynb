{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez0arGqc2mXe"
      },
      "source": [
        "# Simple Auto Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsNA2NoD2uAo"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "tf.random.set_seed(2021)\r\n",
        "np.random.seed(2021)\r\n",
        "from tensorflow.keras.layers import Input, Dense\r\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Riu6eMcj28FF"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from mpl_toolkits.mplot3d import Axes3D\r\n",
        "from matplotlib import cm\r\n",
        "from IPython.display import Image"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFpFGmHf41_L"
      },
      "source": [
        "### MNIST 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu6JPdWp41ZD"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\r\n",
        "\r\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWa56uQl41IZ",
        "outputId": "b4dc71a7-2263-427b-a54a-5a797774cc1e"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\r\n",
        "x_test = x_test.astype('float32') / 255.\r\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\r\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\r\n",
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCekWfGP5hh5"
      },
      "source": [
        "### 인코더와 디코더 - single fully-connected neural layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILIAZtim3e5p"
      },
      "source": [
        "# 인코딩될 표현(representation)의 크기\r\n",
        "encoding_dim = 32\r\n",
        "\r\n",
        "# 입력 플레이스홀더\r\n",
        "input_img = Input(shape=(784,))\r\n",
        "# \"encoded\"는 입력의 인코딩된 표현\r\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\r\n",
        "# \"decoded\"는 입력의 손실있는 재구성 (lossy reconstruction)\r\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\r\n",
        "\r\n",
        "# 입력을 입력의 재구성으로 매핑할 모델\r\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HApVzhvz39dI"
      },
      "source": [
        "# 분리된 인코더 모델\r\n",
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfNHcek_4P6d"
      },
      "source": [
        "# 디코더 모델\r\n",
        "\r\n",
        "# 인코딩된 입력을 위한 플레이스 홀더\r\n",
        "encoded_input = Input(shape=(encoding_dim,))\r\n",
        "# 오토인코더 모델의 마지막 레이어 얻기\r\n",
        "decoder_layer = autoencoder.layers[-1]\r\n",
        "# 디코더 모델 생성\r\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyHF18vO568u"
      },
      "source": [
        "### 학습 설정 및 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTYOL9nM4g4-"
      },
      "source": [
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz-AxuQQ4vBt",
        "outputId": "95e8a05b-b374-4e56-e711-096e778153af"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\r\n",
        "                epochs=500,\r\n",
        "                batch_size=256,\r\n",
        "                shuffle=True,\r\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "235/235 [==============================] - 3s 10ms/step - loss: 0.6939 - val_loss: 0.6938\n",
            "Epoch 2/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6937 - val_loss: 0.6936\n",
            "Epoch 3/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6935 - val_loss: 0.6935\n",
            "Epoch 4/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6934 - val_loss: 0.6933\n",
            "Epoch 5/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6932 - val_loss: 0.6931\n",
            "Epoch 6/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6930 - val_loss: 0.6930\n",
            "Epoch 7/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.6929 - val_loss: 0.6928\n",
            "Epoch 8/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6927 - val_loss: 0.6926\n",
            "Epoch 9/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6926 - val_loss: 0.6925\n",
            "Epoch 10/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.6924 - val_loss: 0.6923\n",
            "Epoch 11/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6922 - val_loss: 0.6921\n",
            "Epoch 12/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6921 - val_loss: 0.6920\n",
            "Epoch 13/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6919 - val_loss: 0.6918\n",
            "Epoch 14/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6917 - val_loss: 0.6917\n",
            "Epoch 15/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6916 - val_loss: 0.6915\n",
            "Epoch 16/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6914 - val_loss: 0.6913\n",
            "Epoch 17/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6913 - val_loss: 0.6912\n",
            "Epoch 18/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6911 - val_loss: 0.6910\n",
            "Epoch 19/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6909 - val_loss: 0.6908\n",
            "Epoch 20/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6908 - val_loss: 0.6907\n",
            "Epoch 21/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6906 - val_loss: 0.6905\n",
            "Epoch 22/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6904 - val_loss: 0.6903\n",
            "Epoch 23/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6903 - val_loss: 0.6902\n",
            "Epoch 24/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6901 - val_loss: 0.6900\n",
            "Epoch 25/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6899 - val_loss: 0.6898\n",
            "Epoch 26/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.6898 - val_loss: 0.6896\n",
            "Epoch 27/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6896 - val_loss: 0.6895\n",
            "Epoch 28/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6894 - val_loss: 0.6893\n",
            "Epoch 29/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6892 - val_loss: 0.6891\n",
            "Epoch 30/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.6890 - val_loss: 0.6889\n",
            "Epoch 31/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6889 - val_loss: 0.6887\n",
            "Epoch 32/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6887 - val_loss: 0.6885\n",
            "Epoch 33/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6885 - val_loss: 0.6884\n",
            "Epoch 34/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6883 - val_loss: 0.6882\n",
            "Epoch 35/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6881 - val_loss: 0.6880\n",
            "Epoch 36/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6879 - val_loss: 0.6878\n",
            "Epoch 37/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6877 - val_loss: 0.6876\n",
            "Epoch 38/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6875 - val_loss: 0.6874\n",
            "Epoch 39/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6873 - val_loss: 0.6871\n",
            "Epoch 40/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6871 - val_loss: 0.6869\n",
            "Epoch 41/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.6869 - val_loss: 0.6867\n",
            "Epoch 42/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6867 - val_loss: 0.6865\n",
            "Epoch 43/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6864 - val_loss: 0.6863\n",
            "Epoch 44/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6862 - val_loss: 0.6860\n",
            "Epoch 45/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6860 - val_loss: 0.6858\n",
            "Epoch 46/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6858 - val_loss: 0.6855\n",
            "Epoch 47/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6855 - val_loss: 0.6853\n",
            "Epoch 48/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6853 - val_loss: 0.6850\n",
            "Epoch 49/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6850 - val_loss: 0.6848\n",
            "Epoch 50/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6848 - val_loss: 0.6845\n",
            "Epoch 51/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6845 - val_loss: 0.6842\n",
            "Epoch 52/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6842 - val_loss: 0.6839\n",
            "Epoch 53/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6839 - val_loss: 0.6837\n",
            "Epoch 54/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6836 - val_loss: 0.6834\n",
            "Epoch 55/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6833 - val_loss: 0.6831\n",
            "Epoch 56/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6830 - val_loss: 0.6827\n",
            "Epoch 57/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.6828 - val_loss: 0.6824\n",
            "Epoch 58/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6824 - val_loss: 0.6821\n",
            "Epoch 59/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6821 - val_loss: 0.6818\n",
            "Epoch 60/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6818 - val_loss: 0.6814\n",
            "Epoch 61/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6814 - val_loss: 0.6811\n",
            "Epoch 62/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6811 - val_loss: 0.6807\n",
            "Epoch 63/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6807 - val_loss: 0.6803\n",
            "Epoch 64/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6803 - val_loss: 0.6799\n",
            "Epoch 65/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6800 - val_loss: 0.6795\n",
            "Epoch 66/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6796 - val_loss: 0.6791\n",
            "Epoch 67/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6792 - val_loss: 0.6787\n",
            "Epoch 68/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6788 - val_loss: 0.6783\n",
            "Epoch 69/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6783 - val_loss: 0.6778\n",
            "Epoch 70/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6778 - val_loss: 0.6774\n",
            "Epoch 71/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6774 - val_loss: 0.6769\n",
            "Epoch 72/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6770 - val_loss: 0.6764\n",
            "Epoch 73/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6765 - val_loss: 0.6759\n",
            "Epoch 74/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6760 - val_loss: 0.6754\n",
            "Epoch 75/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6755 - val_loss: 0.6749\n",
            "Epoch 76/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6750 - val_loss: 0.6744\n",
            "Epoch 77/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6744 - val_loss: 0.6738\n",
            "Epoch 78/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6738 - val_loss: 0.6732\n",
            "Epoch 79/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6733 - val_loss: 0.6727\n",
            "Epoch 80/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6727 - val_loss: 0.6720\n",
            "Epoch 81/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6721 - val_loss: 0.6714\n",
            "Epoch 82/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6715 - val_loss: 0.6708\n",
            "Epoch 83/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6708 - val_loss: 0.6701\n",
            "Epoch 84/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6702 - val_loss: 0.6694\n",
            "Epoch 85/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6695 - val_loss: 0.6687\n",
            "Epoch 86/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6688 - val_loss: 0.6680\n",
            "Epoch 87/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6681 - val_loss: 0.6673\n",
            "Epoch 88/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6673 - val_loss: 0.6665\n",
            "Epoch 89/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6666 - val_loss: 0.6657\n",
            "Epoch 90/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6658 - val_loss: 0.6649\n",
            "Epoch 91/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6650 - val_loss: 0.6641\n",
            "Epoch 92/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6642 - val_loss: 0.6632\n",
            "Epoch 93/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6634 - val_loss: 0.6623\n",
            "Epoch 94/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6625 - val_loss: 0.6614\n",
            "Epoch 95/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6615 - val_loss: 0.6605\n",
            "Epoch 96/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6606 - val_loss: 0.6595\n",
            "Epoch 97/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6597 - val_loss: 0.6586\n",
            "Epoch 98/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6587 - val_loss: 0.6575\n",
            "Epoch 99/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.6576 - val_loss: 0.6565\n",
            "Epoch 100/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.6567 - val_loss: 0.6554\n",
            "Epoch 101/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6556 - val_loss: 0.6543\n",
            "Epoch 102/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6545 - val_loss: 0.6532\n",
            "Epoch 103/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6533 - val_loss: 0.6520\n",
            "Epoch 104/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6522 - val_loss: 0.6508\n",
            "Epoch 105/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6510 - val_loss: 0.6496\n",
            "Epoch 106/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6498 - val_loss: 0.6483\n",
            "Epoch 107/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6486 - val_loss: 0.6470\n",
            "Epoch 108/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6473 - val_loss: 0.6457\n",
            "Epoch 109/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6460 - val_loss: 0.6444\n",
            "Epoch 110/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6446 - val_loss: 0.6430\n",
            "Epoch 111/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6432 - val_loss: 0.6415\n",
            "Epoch 112/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6418 - val_loss: 0.6400\n",
            "Epoch 113/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6404 - val_loss: 0.6385\n",
            "Epoch 114/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6387 - val_loss: 0.6370\n",
            "Epoch 115/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6372 - val_loss: 0.6354\n",
            "Epoch 116/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.6357 - val_loss: 0.6338\n",
            "Epoch 117/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6341 - val_loss: 0.6321\n",
            "Epoch 118/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6326 - val_loss: 0.6304\n",
            "Epoch 119/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.6307 - val_loss: 0.6287\n",
            "Epoch 120/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6290 - val_loss: 0.6269\n",
            "Epoch 121/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6273 - val_loss: 0.6250\n",
            "Epoch 122/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6254 - val_loss: 0.6232\n",
            "Epoch 123/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.6236 - val_loss: 0.6213\n",
            "Epoch 124/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6217 - val_loss: 0.6193\n",
            "Epoch 125/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6197 - val_loss: 0.6173\n",
            "Epoch 126/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.6177 - val_loss: 0.6153\n",
            "Epoch 127/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.6156 - val_loss: 0.6132\n",
            "Epoch 128/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6137 - val_loss: 0.6111\n",
            "Epoch 129/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6116 - val_loss: 0.6089\n",
            "Epoch 130/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6094 - val_loss: 0.6067\n",
            "Epoch 131/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6072 - val_loss: 0.6045\n",
            "Epoch 132/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6050 - val_loss: 0.6022\n",
            "Epoch 133/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6028 - val_loss: 0.5998\n",
            "Epoch 134/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.6004 - val_loss: 0.5975\n",
            "Epoch 135/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5980 - val_loss: 0.5950\n",
            "Epoch 136/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5959 - val_loss: 0.5926\n",
            "Epoch 137/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5934 - val_loss: 0.5901\n",
            "Epoch 138/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5909 - val_loss: 0.5875\n",
            "Epoch 139/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5883 - val_loss: 0.5849\n",
            "Epoch 140/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.5857 - val_loss: 0.5823\n",
            "Epoch 141/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5830 - val_loss: 0.5797\n",
            "Epoch 142/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.5803 - val_loss: 0.5770\n",
            "Epoch 143/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5778 - val_loss: 0.5742\n",
            "Epoch 144/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.5752 - val_loss: 0.5715\n",
            "Epoch 145/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5723 - val_loss: 0.5686\n",
            "Epoch 146/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5694 - val_loss: 0.5658\n",
            "Epoch 147/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5666 - val_loss: 0.5629\n",
            "Epoch 148/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5638 - val_loss: 0.5600\n",
            "Epoch 149/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5609 - val_loss: 0.5571\n",
            "Epoch 150/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5580 - val_loss: 0.5541\n",
            "Epoch 151/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5551 - val_loss: 0.5511\n",
            "Epoch 152/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5523 - val_loss: 0.5481\n",
            "Epoch 153/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5491 - val_loss: 0.5450\n",
            "Epoch 154/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5460 - val_loss: 0.5420\n",
            "Epoch 155/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.5430 - val_loss: 0.5389\n",
            "Epoch 156/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.5399 - val_loss: 0.5357\n",
            "Epoch 157/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5369 - val_loss: 0.5326\n",
            "Epoch 158/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5337 - val_loss: 0.5294\n",
            "Epoch 159/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5306 - val_loss: 0.5263\n",
            "Epoch 160/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5274 - val_loss: 0.5231\n",
            "Epoch 161/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5241 - val_loss: 0.5199\n",
            "Epoch 162/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5214 - val_loss: 0.5167\n",
            "Epoch 163/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.5178 - val_loss: 0.5135\n",
            "Epoch 164/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5147 - val_loss: 0.5102\n",
            "Epoch 165/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5116 - val_loss: 0.5070\n",
            "Epoch 166/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5083 - val_loss: 0.5038\n",
            "Epoch 167/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5050 - val_loss: 0.5005\n",
            "Epoch 168/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.5018 - val_loss: 0.4973\n",
            "Epoch 169/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4986 - val_loss: 0.4941\n",
            "Epoch 170/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4955 - val_loss: 0.4909\n",
            "Epoch 171/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4925 - val_loss: 0.4876\n",
            "Epoch 172/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4891 - val_loss: 0.4844\n",
            "Epoch 173/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4858 - val_loss: 0.4812\n",
            "Epoch 174/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.4828 - val_loss: 0.4780\n",
            "Epoch 175/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.4798 - val_loss: 0.4749\n",
            "Epoch 176/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4765 - val_loss: 0.4717\n",
            "Epoch 177/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.4732 - val_loss: 0.4686\n",
            "Epoch 178/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4699 - val_loss: 0.4654\n",
            "Epoch 179/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4671 - val_loss: 0.4623\n",
            "Epoch 180/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4641 - val_loss: 0.4593\n",
            "Epoch 181/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4607 - val_loss: 0.4562\n",
            "Epoch 182/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.4579 - val_loss: 0.4532\n",
            "Epoch 183/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4548 - val_loss: 0.4502\n",
            "Epoch 184/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4519 - val_loss: 0.4472\n",
            "Epoch 185/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4489 - val_loss: 0.4442\n",
            "Epoch 186/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.4461 - val_loss: 0.4413\n",
            "Epoch 187/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4432 - val_loss: 0.4384\n",
            "Epoch 188/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4403 - val_loss: 0.4356\n",
            "Epoch 189/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4374 - val_loss: 0.4327\n",
            "Epoch 190/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4345 - val_loss: 0.4300\n",
            "Epoch 191/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4320 - val_loss: 0.4272\n",
            "Epoch 192/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.4288 - val_loss: 0.4245\n",
            "Epoch 193/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.4264 - val_loss: 0.4218\n",
            "Epoch 194/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.4238 - val_loss: 0.4192\n",
            "Epoch 195/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4210 - val_loss: 0.4166\n",
            "Epoch 196/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4186 - val_loss: 0.4140\n",
            "Epoch 197/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4157 - val_loss: 0.4114\n",
            "Epoch 198/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.4134 - val_loss: 0.4090\n",
            "Epoch 199/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4110 - val_loss: 0.4065\n",
            "Epoch 200/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4084 - val_loss: 0.4041\n",
            "Epoch 201/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4059 - val_loss: 0.4017\n",
            "Epoch 202/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4040 - val_loss: 0.3994\n",
            "Epoch 203/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.4012 - val_loss: 0.3971\n",
            "Epoch 204/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3993 - val_loss: 0.3948\n",
            "Epoch 205/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3969 - val_loss: 0.3926\n",
            "Epoch 206/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3945 - val_loss: 0.3904\n",
            "Epoch 207/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3924 - val_loss: 0.3883\n",
            "Epoch 208/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3905 - val_loss: 0.3862\n",
            "Epoch 209/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3883 - val_loss: 0.3841\n",
            "Epoch 210/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3864 - val_loss: 0.3821\n",
            "Epoch 211/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3837 - val_loss: 0.3802\n",
            "Epoch 212/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3823 - val_loss: 0.3782\n",
            "Epoch 213/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3802 - val_loss: 0.3763\n",
            "Epoch 214/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3782 - val_loss: 0.3744\n",
            "Epoch 215/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3765 - val_loss: 0.3726\n",
            "Epoch 216/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3748 - val_loss: 0.3708\n",
            "Epoch 217/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3733 - val_loss: 0.3691\n",
            "Epoch 218/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3710 - val_loss: 0.3674\n",
            "Epoch 219/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3697 - val_loss: 0.3657\n",
            "Epoch 220/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3677 - val_loss: 0.3640\n",
            "Epoch 221/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3661 - val_loss: 0.3624\n",
            "Epoch 222/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3641 - val_loss: 0.3608\n",
            "Epoch 223/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3629 - val_loss: 0.3593\n",
            "Epoch 224/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3620 - val_loss: 0.3578\n",
            "Epoch 225/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3601 - val_loss: 0.3563\n",
            "Epoch 226/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3582 - val_loss: 0.3548\n",
            "Epoch 227/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3569 - val_loss: 0.3534\n",
            "Epoch 228/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3555 - val_loss: 0.3520\n",
            "Epoch 229/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3540 - val_loss: 0.3507\n",
            "Epoch 230/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3527 - val_loss: 0.3494\n",
            "Epoch 231/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3513 - val_loss: 0.3481\n",
            "Epoch 232/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3502 - val_loss: 0.3468\n",
            "Epoch 233/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3488 - val_loss: 0.3455\n",
            "Epoch 234/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3478 - val_loss: 0.3443\n",
            "Epoch 235/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3466 - val_loss: 0.3431\n",
            "Epoch 236/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3451 - val_loss: 0.3420\n",
            "Epoch 237/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3440 - val_loss: 0.3409\n",
            "Epoch 238/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3427 - val_loss: 0.3397\n",
            "Epoch 239/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3419 - val_loss: 0.3387\n",
            "Epoch 240/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3405 - val_loss: 0.3376\n",
            "Epoch 241/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3395 - val_loss: 0.3366\n",
            "Epoch 242/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3385 - val_loss: 0.3355\n",
            "Epoch 243/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3374 - val_loss: 0.3345\n",
            "Epoch 244/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3371 - val_loss: 0.3336\n",
            "Epoch 245/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3355 - val_loss: 0.3326\n",
            "Epoch 246/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3345 - val_loss: 0.3317\n",
            "Epoch 247/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3335 - val_loss: 0.3308\n",
            "Epoch 248/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3330 - val_loss: 0.3299\n",
            "Epoch 249/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3319 - val_loss: 0.3290\n",
            "Epoch 250/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3307 - val_loss: 0.3282\n",
            "Epoch 251/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3301 - val_loss: 0.3274\n",
            "Epoch 252/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3293 - val_loss: 0.3265\n",
            "Epoch 253/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3284 - val_loss: 0.3258\n",
            "Epoch 254/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3279 - val_loss: 0.3250\n",
            "Epoch 255/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3268 - val_loss: 0.3242\n",
            "Epoch 256/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3257 - val_loss: 0.3235\n",
            "Epoch 257/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3254 - val_loss: 0.3227\n",
            "Epoch 258/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3244 - val_loss: 0.3220\n",
            "Epoch 259/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3236 - val_loss: 0.3213\n",
            "Epoch 260/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3230 - val_loss: 0.3207\n",
            "Epoch 261/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3223 - val_loss: 0.3200\n",
            "Epoch 262/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3218 - val_loss: 0.3193\n",
            "Epoch 263/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3217 - val_loss: 0.3187\n",
            "Epoch 264/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3205 - val_loss: 0.3181\n",
            "Epoch 265/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3198 - val_loss: 0.3175\n",
            "Epoch 266/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3194 - val_loss: 0.3169\n",
            "Epoch 267/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3187 - val_loss: 0.3163\n",
            "Epoch 268/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3179 - val_loss: 0.3157\n",
            "Epoch 269/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3176 - val_loss: 0.3151\n",
            "Epoch 270/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3167 - val_loss: 0.3146\n",
            "Epoch 271/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3165 - val_loss: 0.3140\n",
            "Epoch 272/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3159 - val_loss: 0.3135\n",
            "Epoch 273/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3151 - val_loss: 0.3130\n",
            "Epoch 274/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3147 - val_loss: 0.3125\n",
            "Epoch 275/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3141 - val_loss: 0.3120\n",
            "Epoch 276/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3139 - val_loss: 0.3115\n",
            "Epoch 277/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3136 - val_loss: 0.3110\n",
            "Epoch 278/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3126 - val_loss: 0.3106\n",
            "Epoch 279/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3121 - val_loss: 0.3101\n",
            "Epoch 280/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3115 - val_loss: 0.3096\n",
            "Epoch 281/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3118 - val_loss: 0.3092\n",
            "Epoch 282/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3111 - val_loss: 0.3088\n",
            "Epoch 283/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3105 - val_loss: 0.3083\n",
            "Epoch 284/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3098 - val_loss: 0.3079\n",
            "Epoch 285/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3094 - val_loss: 0.3075\n",
            "Epoch 286/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3092 - val_loss: 0.3071\n",
            "Epoch 287/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3091 - val_loss: 0.3067\n",
            "Epoch 288/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3086 - val_loss: 0.3063\n",
            "Epoch 289/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3078 - val_loss: 0.3060\n",
            "Epoch 290/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3079 - val_loss: 0.3056\n",
            "Epoch 291/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3071 - val_loss: 0.3052\n",
            "Epoch 292/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3068 - val_loss: 0.3049\n",
            "Epoch 293/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3066 - val_loss: 0.3045\n",
            "Epoch 294/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3060 - val_loss: 0.3042\n",
            "Epoch 295/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3057 - val_loss: 0.3038\n",
            "Epoch 296/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3054 - val_loss: 0.3035\n",
            "Epoch 297/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3050 - val_loss: 0.3032\n",
            "Epoch 298/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3050 - val_loss: 0.3029\n",
            "Epoch 299/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3041 - val_loss: 0.3025\n",
            "Epoch 300/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3039 - val_loss: 0.3022\n",
            "Epoch 301/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3038 - val_loss: 0.3019\n",
            "Epoch 302/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3034 - val_loss: 0.3016\n",
            "Epoch 303/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3032 - val_loss: 0.3013\n",
            "Epoch 304/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3030 - val_loss: 0.3010\n",
            "Epoch 305/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3023 - val_loss: 0.3008\n",
            "Epoch 306/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3024 - val_loss: 0.3005\n",
            "Epoch 307/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3022 - val_loss: 0.3002\n",
            "Epoch 308/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3016 - val_loss: 0.2999\n",
            "Epoch 309/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3016 - val_loss: 0.2997\n",
            "Epoch 310/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3010 - val_loss: 0.2994\n",
            "Epoch 311/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3009 - val_loss: 0.2991\n",
            "Epoch 312/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3005 - val_loss: 0.2989\n",
            "Epoch 313/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.3003 - val_loss: 0.2986\n",
            "Epoch 314/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.3000 - val_loss: 0.2984\n",
            "Epoch 315/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2997 - val_loss: 0.2982\n",
            "Epoch 316/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2996 - val_loss: 0.2979\n",
            "Epoch 317/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2995 - val_loss: 0.2977\n",
            "Epoch 318/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2988 - val_loss: 0.2975\n",
            "Epoch 319/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2987 - val_loss: 0.2972\n",
            "Epoch 320/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2985 - val_loss: 0.2970\n",
            "Epoch 321/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2984 - val_loss: 0.2968\n",
            "Epoch 322/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2983 - val_loss: 0.2966\n",
            "Epoch 323/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2979 - val_loss: 0.2963\n",
            "Epoch 324/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2976 - val_loss: 0.2961\n",
            "Epoch 325/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2975 - val_loss: 0.2959\n",
            "Epoch 326/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2974 - val_loss: 0.2957\n",
            "Epoch 327/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2972 - val_loss: 0.2955\n",
            "Epoch 328/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2970 - val_loss: 0.2953\n",
            "Epoch 329/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2971 - val_loss: 0.2951\n",
            "Epoch 330/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2966 - val_loss: 0.2949\n",
            "Epoch 331/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2962 - val_loss: 0.2948\n",
            "Epoch 332/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2960 - val_loss: 0.2946\n",
            "Epoch 333/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2959 - val_loss: 0.2944\n",
            "Epoch 334/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2957 - val_loss: 0.2942\n",
            "Epoch 335/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2954 - val_loss: 0.2940\n",
            "Epoch 336/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2953 - val_loss: 0.2938\n",
            "Epoch 337/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2953 - val_loss: 0.2937\n",
            "Epoch 338/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2949 - val_loss: 0.2935\n",
            "Epoch 339/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2949 - val_loss: 0.2933\n",
            "Epoch 340/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2946 - val_loss: 0.2932\n",
            "Epoch 341/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2946 - val_loss: 0.2930\n",
            "Epoch 342/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2944 - val_loss: 0.2928\n",
            "Epoch 343/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2943 - val_loss: 0.2927\n",
            "Epoch 344/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2939 - val_loss: 0.2925\n",
            "Epoch 345/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2940 - val_loss: 0.2923\n",
            "Epoch 346/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2935 - val_loss: 0.2922\n",
            "Epoch 347/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2933 - val_loss: 0.2920\n",
            "Epoch 348/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2935 - val_loss: 0.2919\n",
            "Epoch 349/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2930 - val_loss: 0.2917\n",
            "Epoch 350/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2932 - val_loss: 0.2916\n",
            "Epoch 351/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2927 - val_loss: 0.2914\n",
            "Epoch 352/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2928 - val_loss: 0.2913\n",
            "Epoch 353/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2927 - val_loss: 0.2912\n",
            "Epoch 354/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2924 - val_loss: 0.2910\n",
            "Epoch 355/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2925 - val_loss: 0.2909\n",
            "Epoch 356/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2922 - val_loss: 0.2907\n",
            "Epoch 357/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2918 - val_loss: 0.2906\n",
            "Epoch 358/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2921 - val_loss: 0.2905\n",
            "Epoch 359/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2916 - val_loss: 0.2903\n",
            "Epoch 360/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2916 - val_loss: 0.2902\n",
            "Epoch 361/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2914 - val_loss: 0.2901\n",
            "Epoch 362/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2915 - val_loss: 0.2900\n",
            "Epoch 363/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2913 - val_loss: 0.2898\n",
            "Epoch 364/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2910 - val_loss: 0.2897\n",
            "Epoch 365/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2909 - val_loss: 0.2896\n",
            "Epoch 366/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2907 - val_loss: 0.2895\n",
            "Epoch 367/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2909 - val_loss: 0.2893\n",
            "Epoch 368/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2904 - val_loss: 0.2892\n",
            "Epoch 369/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2910 - val_loss: 0.2891\n",
            "Epoch 370/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2905 - val_loss: 0.2890\n",
            "Epoch 371/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2903 - val_loss: 0.2889\n",
            "Epoch 372/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2898 - val_loss: 0.2888\n",
            "Epoch 373/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2903 - val_loss: 0.2887\n",
            "Epoch 374/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2898 - val_loss: 0.2885\n",
            "Epoch 375/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2893 - val_loss: 0.2884\n",
            "Epoch 376/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2895 - val_loss: 0.2883\n",
            "Epoch 377/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2898 - val_loss: 0.2882\n",
            "Epoch 378/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2892 - val_loss: 0.2881\n",
            "Epoch 379/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2893 - val_loss: 0.2880\n",
            "Epoch 380/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2891 - val_loss: 0.2879\n",
            "Epoch 381/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2891 - val_loss: 0.2878\n",
            "Epoch 382/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2886 - val_loss: 0.2877\n",
            "Epoch 383/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2891 - val_loss: 0.2876\n",
            "Epoch 384/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2885 - val_loss: 0.2875\n",
            "Epoch 385/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2887 - val_loss: 0.2874\n",
            "Epoch 386/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2887 - val_loss: 0.2873\n",
            "Epoch 387/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2882 - val_loss: 0.2872\n",
            "Epoch 388/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2884 - val_loss: 0.2871\n",
            "Epoch 389/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2888 - val_loss: 0.2870\n",
            "Epoch 390/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2882 - val_loss: 0.2869\n",
            "Epoch 391/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2886 - val_loss: 0.2868\n",
            "Epoch 392/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2879 - val_loss: 0.2867\n",
            "Epoch 393/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2876 - val_loss: 0.2866\n",
            "Epoch 394/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2877 - val_loss: 0.2865\n",
            "Epoch 395/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2877 - val_loss: 0.2865\n",
            "Epoch 396/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2878 - val_loss: 0.2864\n",
            "Epoch 397/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2873 - val_loss: 0.2863\n",
            "Epoch 398/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2877 - val_loss: 0.2862\n",
            "Epoch 399/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2877 - val_loss: 0.2861\n",
            "Epoch 400/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2874 - val_loss: 0.2860\n",
            "Epoch 401/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2874 - val_loss: 0.2859\n",
            "Epoch 402/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2872 - val_loss: 0.2859\n",
            "Epoch 403/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2872 - val_loss: 0.2858\n",
            "Epoch 404/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2864 - val_loss: 0.2857\n",
            "Epoch 405/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2870 - val_loss: 0.2856\n",
            "Epoch 406/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2866 - val_loss: 0.2855\n",
            "Epoch 407/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2867 - val_loss: 0.2854\n",
            "Epoch 408/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2861 - val_loss: 0.2854\n",
            "Epoch 409/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2866 - val_loss: 0.2853\n",
            "Epoch 410/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2864 - val_loss: 0.2852\n",
            "Epoch 411/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2866 - val_loss: 0.2851\n",
            "Epoch 412/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2862 - val_loss: 0.2851\n",
            "Epoch 413/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2861 - val_loss: 0.2850\n",
            "Epoch 414/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2862 - val_loss: 0.2849\n",
            "Epoch 415/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2857 - val_loss: 0.2848\n",
            "Epoch 416/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2856 - val_loss: 0.2848\n",
            "Epoch 417/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2860 - val_loss: 0.2847\n",
            "Epoch 418/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2858 - val_loss: 0.2846\n",
            "Epoch 419/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2860 - val_loss: 0.2845\n",
            "Epoch 420/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2856 - val_loss: 0.2845\n",
            "Epoch 421/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2860 - val_loss: 0.2844\n",
            "Epoch 422/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2858 - val_loss: 0.2843\n",
            "Epoch 423/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2856 - val_loss: 0.2843\n",
            "Epoch 424/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2854 - val_loss: 0.2842\n",
            "Epoch 425/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2857 - val_loss: 0.2841\n",
            "Epoch 426/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2854 - val_loss: 0.2841\n",
            "Epoch 427/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2854 - val_loss: 0.2840\n",
            "Epoch 428/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2852 - val_loss: 0.2839\n",
            "Epoch 429/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2852 - val_loss: 0.2839\n",
            "Epoch 430/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2850 - val_loss: 0.2838\n",
            "Epoch 431/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2849 - val_loss: 0.2837\n",
            "Epoch 432/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2848 - val_loss: 0.2837\n",
            "Epoch 433/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2851 - val_loss: 0.2836\n",
            "Epoch 434/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2846 - val_loss: 0.2835\n",
            "Epoch 435/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2846 - val_loss: 0.2835\n",
            "Epoch 436/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2846 - val_loss: 0.2834\n",
            "Epoch 437/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.2848 - val_loss: 0.2833\n",
            "Epoch 438/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2845 - val_loss: 0.2833\n",
            "Epoch 439/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2845 - val_loss: 0.2832\n",
            "Epoch 440/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2844 - val_loss: 0.2832\n",
            "Epoch 441/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2841 - val_loss: 0.2831\n",
            "Epoch 442/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2840 - val_loss: 0.2830\n",
            "Epoch 443/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2839 - val_loss: 0.2830\n",
            "Epoch 444/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2842 - val_loss: 0.2829\n",
            "Epoch 445/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2841 - val_loss: 0.2829\n",
            "Epoch 446/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2837 - val_loss: 0.2828\n",
            "Epoch 447/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2837 - val_loss: 0.2827\n",
            "Epoch 448/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2838 - val_loss: 0.2827\n",
            "Epoch 449/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2838 - val_loss: 0.2826\n",
            "Epoch 450/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2837 - val_loss: 0.2826\n",
            "Epoch 451/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2836 - val_loss: 0.2825\n",
            "Epoch 452/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2836 - val_loss: 0.2825\n",
            "Epoch 453/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2838 - val_loss: 0.2824\n",
            "Epoch 454/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2833 - val_loss: 0.2824\n",
            "Epoch 455/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2835 - val_loss: 0.2823\n",
            "Epoch 456/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2838 - val_loss: 0.2822\n",
            "Epoch 457/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2831 - val_loss: 0.2822\n",
            "Epoch 458/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2834 - val_loss: 0.2821\n",
            "Epoch 459/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2831 - val_loss: 0.2821\n",
            "Epoch 460/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2831 - val_loss: 0.2820\n",
            "Epoch 461/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2835 - val_loss: 0.2820\n",
            "Epoch 462/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2827 - val_loss: 0.2819\n",
            "Epoch 463/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2827 - val_loss: 0.2819\n",
            "Epoch 464/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2830 - val_loss: 0.2818\n",
            "Epoch 465/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2829 - val_loss: 0.2818\n",
            "Epoch 466/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2826 - val_loss: 0.2817\n",
            "Epoch 467/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2828 - val_loss: 0.2817\n",
            "Epoch 468/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2827 - val_loss: 0.2816\n",
            "Epoch 469/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2828 - val_loss: 0.2816\n",
            "Epoch 470/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2827 - val_loss: 0.2815\n",
            "Epoch 471/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2828 - val_loss: 0.2815\n",
            "Epoch 472/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2826 - val_loss: 0.2814\n",
            "Epoch 473/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2826 - val_loss: 0.2814\n",
            "Epoch 474/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2826 - val_loss: 0.2813\n",
            "Epoch 475/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2825 - val_loss: 0.2813\n",
            "Epoch 476/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2822 - val_loss: 0.2812\n",
            "Epoch 477/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2823 - val_loss: 0.2812\n",
            "Epoch 478/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2825 - val_loss: 0.2811\n",
            "Epoch 479/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2820 - val_loss: 0.2811\n",
            "Epoch 480/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2826 - val_loss: 0.2811\n",
            "Epoch 481/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2819 - val_loss: 0.2810\n",
            "Epoch 482/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2821 - val_loss: 0.2810\n",
            "Epoch 483/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2822 - val_loss: 0.2809\n",
            "Epoch 484/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2814 - val_loss: 0.2809\n",
            "Epoch 485/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2814 - val_loss: 0.2808\n",
            "Epoch 486/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2817 - val_loss: 0.2808\n",
            "Epoch 487/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2817 - val_loss: 0.2807\n",
            "Epoch 488/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2820 - val_loss: 0.2807\n",
            "Epoch 489/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2820 - val_loss: 0.2807\n",
            "Epoch 490/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2819 - val_loss: 0.2806\n",
            "Epoch 491/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2817 - val_loss: 0.2806\n",
            "Epoch 492/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2814 - val_loss: 0.2805\n",
            "Epoch 493/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2816 - val_loss: 0.2805\n",
            "Epoch 494/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2814 - val_loss: 0.2804\n",
            "Epoch 495/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2815 - val_loss: 0.2804\n",
            "Epoch 496/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2817 - val_loss: 0.2804\n",
            "Epoch 497/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2813 - val_loss: 0.2803\n",
            "Epoch 498/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2817 - val_loss: 0.2803\n",
            "Epoch 499/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2814 - val_loss: 0.2802\n",
            "Epoch 500/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.2811 - val_loss: 0.2802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4da446a090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSFDi1gZ6NhN"
      },
      "source": [
        "### 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbPgh-Bo6KWL"
      },
      "source": [
        "encoded_imgs = encoder.predict(x_test)\r\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J-A52Q851br"
      },
      "source": [
        "### 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "dU4X2jB55RAV",
        "outputId": "8b699cb4-e1e6-4e98-b002-c5e2c85f2d16"
      },
      "source": [
        "n = 10  # 몇 개의 숫자를 나타낼 것인지\r\n",
        "plt.figure(figsize=(20, 4))\r\n",
        "for i in range(n):\r\n",
        "    # 원본 데이터\r\n",
        "    ax = plt.subplot(2, n, i + 1)\r\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "\r\n",
        "    # 재구성된 데이터\r\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\r\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bu64pjU6GJ0"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}