{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_MNIST_sparsity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez0arGqc2mXe"
      },
      "source": [
        "# Simple Auto Encoder\r\n",
        "- Adding a sparsity constraint on the encoded representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsNA2NoD2uAo"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "tf.random.set_seed(2021)\r\n",
        "np.random.seed(2021)\r\n",
        "\r\n",
        "from tensorflow.keras.layers import Input, Dense\r\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Riu6eMcj28FF"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from mpl_toolkits.mplot3d import Axes3D\r\n",
        "from matplotlib import cm\r\n",
        "from IPython.display import Image"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFpFGmHf41_L"
      },
      "source": [
        "### MNIST 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu6JPdWp41ZD",
        "outputId": "ec530623-59bf-4c0f-85e0-9674eed7b535"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\r\n",
        "\r\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWa56uQl41IZ",
        "outputId": "59434e54-d3bc-4750-c3a0-54a93a0a5b3d"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\r\n",
        "x_test = x_test.astype('float32') / 255.\r\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\r\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\r\n",
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCekWfGP5hh5"
      },
      "source": [
        "### 인코더와 디코더 - single fully-connected neural layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILIAZtim3e5p"
      },
      "source": [
        "from tensorflow.keras import regularizers\r\n",
        "\r\n",
        "encoding_dim = 32\r\n",
        "\r\n",
        "input_img = Input(shape=(784,))\r\n",
        "# L1 activity regularizer를 Dense layer에 추가 \r\n",
        "encoded = Dense(encoding_dim, activation='relu',\r\n",
        "                activity_regularizer=regularizers.l1(10e-5))(input_img)\r\n",
        "# \"decoded\"는 입력의 손실있는 재구성 (lossy reconstruction)\r\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\r\n",
        "\r\n",
        "# 입력을 입력의 재구성으로 매핑할 모델\r\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HApVzhvz39dI"
      },
      "source": [
        "# 분리된 인코더 모델\r\n",
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfNHcek_4P6d"
      },
      "source": [
        "# 디코더 모델\r\n",
        "\r\n",
        "# 인코딩된 입력을 위한 플레이스 홀더\r\n",
        "encoded_input = Input(shape=(encoding_dim,))\r\n",
        "# 오토인코더 모델의 마지막 레이어 얻기\r\n",
        "decoder_layer = autoencoder.layers[-1]\r\n",
        "# 디코더 모델 생성\r\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyHF18vO568u"
      },
      "source": [
        "### 학습 설정 및 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTYOL9nM4g4-"
      },
      "source": [
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz-AxuQQ4vBt",
        "outputId": "0afab16d-d42d-464e-d474-5b5a7b8f1317"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\r\n",
        "                epochs=1000,\r\n",
        "                batch_size=256,\r\n",
        "                shuffle=True,\r\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "235/235 [==============================] - 4s 5ms/step - loss: 0.6945 - val_loss: 0.6945\n",
            "Epoch 2/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6944 - val_loss: 0.6943\n",
            "Epoch 3/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6942 - val_loss: 0.6941\n",
            "Epoch 4/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6940 - val_loss: 0.6939\n",
            "Epoch 5/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6938 - val_loss: 0.6938\n",
            "Epoch 6/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6937 - val_loss: 0.6936\n",
            "Epoch 7/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6935 - val_loss: 0.6934\n",
            "Epoch 8/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6933 - val_loss: 0.6933\n",
            "Epoch 9/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6932 - val_loss: 0.6931\n",
            "Epoch 10/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6930 - val_loss: 0.6929\n",
            "Epoch 11/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6929 - val_loss: 0.6928\n",
            "Epoch 12/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6927 - val_loss: 0.6926\n",
            "Epoch 13/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6925 - val_loss: 0.6925\n",
            "Epoch 14/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6924 - val_loss: 0.6923\n",
            "Epoch 15/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6922 - val_loss: 0.6921\n",
            "Epoch 16/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6921 - val_loss: 0.6920\n",
            "Epoch 17/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6919 - val_loss: 0.6918\n",
            "Epoch 18/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6918 - val_loss: 0.6917\n",
            "Epoch 19/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6916 - val_loss: 0.6915\n",
            "Epoch 20/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6914 - val_loss: 0.6913\n",
            "Epoch 21/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6913 - val_loss: 0.6912\n",
            "Epoch 22/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6911 - val_loss: 0.6910\n",
            "Epoch 23/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6910 - val_loss: 0.6909\n",
            "Epoch 24/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6908 - val_loss: 0.6907\n",
            "Epoch 25/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6907 - val_loss: 0.6905\n",
            "Epoch 26/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6905 - val_loss: 0.6904\n",
            "Epoch 27/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6903 - val_loss: 0.6902\n",
            "Epoch 28/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6902 - val_loss: 0.6901\n",
            "Epoch 29/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6900 - val_loss: 0.6899\n",
            "Epoch 30/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6898 - val_loss: 0.6897\n",
            "Epoch 31/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6897 - val_loss: 0.6896\n",
            "Epoch 32/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6895 - val_loss: 0.6894\n",
            "Epoch 33/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6893 - val_loss: 0.6892\n",
            "Epoch 34/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6892 - val_loss: 0.6890\n",
            "Epoch 35/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6890 - val_loss: 0.6889\n",
            "Epoch 36/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6888 - val_loss: 0.6887\n",
            "Epoch 37/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6886 - val_loss: 0.6885\n",
            "Epoch 38/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6884 - val_loss: 0.6883\n",
            "Epoch 39/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6883 - val_loss: 0.6881\n",
            "Epoch 40/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6881 - val_loss: 0.6879\n",
            "Epoch 41/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6879 - val_loss: 0.6877\n",
            "Epoch 42/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6877 - val_loss: 0.6875\n",
            "Epoch 43/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6875 - val_loss: 0.6873\n",
            "Epoch 44/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6873 - val_loss: 0.6871\n",
            "Epoch 45/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6871 - val_loss: 0.6869\n",
            "Epoch 46/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6869 - val_loss: 0.6867\n",
            "Epoch 47/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6867 - val_loss: 0.6865\n",
            "Epoch 48/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6865 - val_loss: 0.6863\n",
            "Epoch 49/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6862 - val_loss: 0.6860\n",
            "Epoch 50/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6860 - val_loss: 0.6858\n",
            "Epoch 51/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6858 - val_loss: 0.6856\n",
            "Epoch 52/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6855 - val_loss: 0.6853\n",
            "Epoch 53/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6853 - val_loss: 0.6851\n",
            "Epoch 54/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6851 - val_loss: 0.6848\n",
            "Epoch 55/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6848 - val_loss: 0.6846\n",
            "Epoch 56/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6846 - val_loss: 0.6843\n",
            "Epoch 57/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6843 - val_loss: 0.6840\n",
            "Epoch 58/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6840 - val_loss: 0.6838\n",
            "Epoch 59/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6837 - val_loss: 0.6835\n",
            "Epoch 60/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6835 - val_loss: 0.6832\n",
            "Epoch 61/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6832 - val_loss: 0.6829\n",
            "Epoch 62/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6829 - val_loss: 0.6826\n",
            "Epoch 63/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6826 - val_loss: 0.6823\n",
            "Epoch 64/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6823 - val_loss: 0.6819\n",
            "Epoch 65/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6820 - val_loss: 0.6816\n",
            "Epoch 66/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6816 - val_loss: 0.6813\n",
            "Epoch 67/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6813 - val_loss: 0.6809\n",
            "Epoch 68/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6809 - val_loss: 0.6806\n",
            "Epoch 69/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6806 - val_loss: 0.6802\n",
            "Epoch 70/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6802 - val_loss: 0.6798\n",
            "Epoch 71/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6798 - val_loss: 0.6794\n",
            "Epoch 72/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6795 - val_loss: 0.6790\n",
            "Epoch 73/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6791 - val_loss: 0.6786\n",
            "Epoch 74/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6786 - val_loss: 0.6782\n",
            "Epoch 75/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6782 - val_loss: 0.6777\n",
            "Epoch 76/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6778 - val_loss: 0.6773\n",
            "Epoch 77/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6773 - val_loss: 0.6768\n",
            "Epoch 78/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6769 - val_loss: 0.6764\n",
            "Epoch 79/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6764 - val_loss: 0.6759\n",
            "Epoch 80/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6759 - val_loss: 0.6754\n",
            "Epoch 81/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6754 - val_loss: 0.6749\n",
            "Epoch 82/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6749 - val_loss: 0.6743\n",
            "Epoch 83/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6743 - val_loss: 0.6738\n",
            "Epoch 84/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6738 - val_loss: 0.6732\n",
            "Epoch 85/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6733 - val_loss: 0.6726\n",
            "Epoch 86/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6727 - val_loss: 0.6720\n",
            "Epoch 87/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6721 - val_loss: 0.6714\n",
            "Epoch 88/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6715 - val_loss: 0.6708\n",
            "Epoch 89/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6708 - val_loss: 0.6701\n",
            "Epoch 90/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6702 - val_loss: 0.6695\n",
            "Epoch 91/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6696 - val_loss: 0.6688\n",
            "Epoch 92/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6688 - val_loss: 0.6681\n",
            "Epoch 93/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6682 - val_loss: 0.6673\n",
            "Epoch 94/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6674 - val_loss: 0.6666\n",
            "Epoch 95/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6667 - val_loss: 0.6658\n",
            "Epoch 96/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6659 - val_loss: 0.6650\n",
            "Epoch 97/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6651 - val_loss: 0.6642\n",
            "Epoch 98/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6643 - val_loss: 0.6634\n",
            "Epoch 99/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6634 - val_loss: 0.6625\n",
            "Epoch 100/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6626 - val_loss: 0.6616\n",
            "Epoch 101/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6618 - val_loss: 0.6607\n",
            "Epoch 102/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6608 - val_loss: 0.6598\n",
            "Epoch 103/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6599 - val_loss: 0.6588\n",
            "Epoch 104/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6589 - val_loss: 0.6578\n",
            "Epoch 105/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6579 - val_loss: 0.6568\n",
            "Epoch 106/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6569 - val_loss: 0.6557\n",
            "Epoch 107/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6559 - val_loss: 0.6547\n",
            "Epoch 108/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6548 - val_loss: 0.6535\n",
            "Epoch 109/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6537 - val_loss: 0.6524\n",
            "Epoch 110/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6526 - val_loss: 0.6512\n",
            "Epoch 111/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6514 - val_loss: 0.6500\n",
            "Epoch 112/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6502 - val_loss: 0.6488\n",
            "Epoch 113/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6491 - val_loss: 0.6475\n",
            "Epoch 114/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6477 - val_loss: 0.6462\n",
            "Epoch 115/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6464 - val_loss: 0.6449\n",
            "Epoch 116/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6451 - val_loss: 0.6435\n",
            "Epoch 117/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6438 - val_loss: 0.6421\n",
            "Epoch 118/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6425 - val_loss: 0.6407\n",
            "Epoch 119/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6409 - val_loss: 0.6392\n",
            "Epoch 120/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6395 - val_loss: 0.6377\n",
            "Epoch 121/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6380 - val_loss: 0.6362\n",
            "Epoch 122/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6364 - val_loss: 0.6346\n",
            "Epoch 123/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6349 - val_loss: 0.6329\n",
            "Epoch 124/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6333 - val_loss: 0.6313\n",
            "Epoch 125/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6316 - val_loss: 0.6296\n",
            "Epoch 126/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6299 - val_loss: 0.6278\n",
            "Epoch 127/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6281 - val_loss: 0.6261\n",
            "Epoch 128/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6264 - val_loss: 0.6242\n",
            "Epoch 129/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6246 - val_loss: 0.6224\n",
            "Epoch 130/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6228 - val_loss: 0.6205\n",
            "Epoch 131/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6208 - val_loss: 0.6185\n",
            "Epoch 132/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6189 - val_loss: 0.6165\n",
            "Epoch 133/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6170 - val_loss: 0.6145\n",
            "Epoch 134/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6150 - val_loss: 0.6125\n",
            "Epoch 135/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6129 - val_loss: 0.6103\n",
            "Epoch 136/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6110 - val_loss: 0.6082\n",
            "Epoch 137/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6088 - val_loss: 0.6060\n",
            "Epoch 138/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6067 - val_loss: 0.6038\n",
            "Epoch 139/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6044 - val_loss: 0.6015\n",
            "Epoch 140/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.6021 - val_loss: 0.5992\n",
            "Epoch 141/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5997 - val_loss: 0.5968\n",
            "Epoch 142/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5973 - val_loss: 0.5944\n",
            "Epoch 143/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5951 - val_loss: 0.5920\n",
            "Epoch 144/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5928 - val_loss: 0.5895\n",
            "Epoch 145/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5902 - val_loss: 0.5870\n",
            "Epoch 146/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5876 - val_loss: 0.5845\n",
            "Epoch 147/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5851 - val_loss: 0.5819\n",
            "Epoch 148/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5826 - val_loss: 0.5793\n",
            "Epoch 149/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5800 - val_loss: 0.5766\n",
            "Epoch 150/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5774 - val_loss: 0.5739\n",
            "Epoch 151/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5747 - val_loss: 0.5712\n",
            "Epoch 152/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5721 - val_loss: 0.5684\n",
            "Epoch 153/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5693 - val_loss: 0.5656\n",
            "Epoch 154/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5664 - val_loss: 0.5628\n",
            "Epoch 155/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5637 - val_loss: 0.5599\n",
            "Epoch 156/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5608 - val_loss: 0.5571\n",
            "Epoch 157/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5580 - val_loss: 0.5541\n",
            "Epoch 158/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5551 - val_loss: 0.5512\n",
            "Epoch 159/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5521 - val_loss: 0.5482\n",
            "Epoch 160/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5492 - val_loss: 0.5453\n",
            "Epoch 161/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5461 - val_loss: 0.5422\n",
            "Epoch 162/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5435 - val_loss: 0.5392\n",
            "Epoch 163/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5401 - val_loss: 0.5362\n",
            "Epoch 164/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5372 - val_loss: 0.5331\n",
            "Epoch 165/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5343 - val_loss: 0.5300\n",
            "Epoch 166/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5312 - val_loss: 0.5269\n",
            "Epoch 167/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5279 - val_loss: 0.5238\n",
            "Epoch 168/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5249 - val_loss: 0.5207\n",
            "Epoch 169/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5218 - val_loss: 0.5176\n",
            "Epoch 170/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5188 - val_loss: 0.5144\n",
            "Epoch 171/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5159 - val_loss: 0.5113\n",
            "Epoch 172/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5126 - val_loss: 0.5081\n",
            "Epoch 173/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5093 - val_loss: 0.5050\n",
            "Epoch 174/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5063 - val_loss: 0.5019\n",
            "Epoch 175/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5034 - val_loss: 0.4987\n",
            "Epoch 176/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5002 - val_loss: 0.4956\n",
            "Epoch 177/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4969 - val_loss: 0.4924\n",
            "Epoch 178/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4936 - val_loss: 0.4893\n",
            "Epoch 179/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4908 - val_loss: 0.4862\n",
            "Epoch 180/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4878 - val_loss: 0.4831\n",
            "Epoch 181/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4843 - val_loss: 0.4800\n",
            "Epoch 182/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4815 - val_loss: 0.4769\n",
            "Epoch 183/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4784 - val_loss: 0.4739\n",
            "Epoch 184/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4754 - val_loss: 0.4708\n",
            "Epoch 185/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4723 - val_loss: 0.4678\n",
            "Epoch 186/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4695 - val_loss: 0.4648\n",
            "Epoch 187/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4665 - val_loss: 0.4618\n",
            "Epoch 188/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4635 - val_loss: 0.4588\n",
            "Epoch 189/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4605 - val_loss: 0.4559\n",
            "Epoch 190/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4575 - val_loss: 0.4530\n",
            "Epoch 191/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4549 - val_loss: 0.4501\n",
            "Epoch 192/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4516 - val_loss: 0.4473\n",
            "Epoch 193/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4490 - val_loss: 0.4445\n",
            "Epoch 194/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4463 - val_loss: 0.4417\n",
            "Epoch 195/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4434 - val_loss: 0.4389\n",
            "Epoch 196/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4408 - val_loss: 0.4362\n",
            "Epoch 197/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4377 - val_loss: 0.4335\n",
            "Epoch 198/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4353 - val_loss: 0.4308\n",
            "Epoch 199/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4327 - val_loss: 0.4282\n",
            "Epoch 200/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4299 - val_loss: 0.4256\n",
            "Epoch 201/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4273 - val_loss: 0.4230\n",
            "Epoch 202/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4252 - val_loss: 0.4205\n",
            "Epoch 203/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4223 - val_loss: 0.4180\n",
            "Epoch 204/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4202 - val_loss: 0.4156\n",
            "Epoch 205/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4175 - val_loss: 0.4132\n",
            "Epoch 206/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.4108\n",
            "Epoch 207/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.4085\n",
            "Epoch 208/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4062\n",
            "Epoch 209/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4082 - val_loss: 0.4040\n",
            "Epoch 210/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4061 - val_loss: 0.4017\n",
            "Epoch 211/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4032 - val_loss: 0.3996\n",
            "Epoch 212/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.3974\n",
            "Epoch 213/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3993 - val_loss: 0.3953\n",
            "Epoch 214/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3971 - val_loss: 0.3933\n",
            "Epoch 215/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3952 - val_loss: 0.3912\n",
            "Epoch 216/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3933 - val_loss: 0.3893\n",
            "Epoch 217/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3916 - val_loss: 0.3873\n",
            "Epoch 218/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3891 - val_loss: 0.3854\n",
            "Epoch 219/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3876 - val_loss: 0.3835\n",
            "Epoch 220/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3855 - val_loss: 0.3817\n",
            "Epoch 221/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.3799\n",
            "Epoch 222/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3815 - val_loss: 0.3781\n",
            "Epoch 223/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3801 - val_loss: 0.3764\n",
            "Epoch 224/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3790 - val_loss: 0.3747\n",
            "Epoch 225/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.3730\n",
            "Epoch 226/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.3714\n",
            "Epoch 227/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3734 - val_loss: 0.3698\n",
            "Epoch 228/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3718 - val_loss: 0.3683\n",
            "Epoch 229/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3702 - val_loss: 0.3667\n",
            "Epoch 230/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.3652\n",
            "Epoch 231/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 0.3638\n",
            "Epoch 232/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3658 - val_loss: 0.3623\n",
            "Epoch 233/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3642 - val_loss: 0.3609\n",
            "Epoch 234/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3632 - val_loss: 0.3596\n",
            "Epoch 235/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.3582\n",
            "Epoch 236/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3601 - val_loss: 0.3569\n",
            "Epoch 237/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3589 - val_loss: 0.3556\n",
            "Epoch 238/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.3544\n",
            "Epoch 239/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3564 - val_loss: 0.3532\n",
            "Epoch 240/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3550 - val_loss: 0.3520\n",
            "Epoch 241/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3538 - val_loss: 0.3508\n",
            "Epoch 242/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3527 - val_loss: 0.3496\n",
            "Epoch 243/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3514 - val_loss: 0.3485\n",
            "Epoch 244/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.3474\n",
            "Epoch 245/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3493 - val_loss: 0.3463\n",
            "Epoch 246/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3482 - val_loss: 0.3453\n",
            "Epoch 247/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3470 - val_loss: 0.3443\n",
            "Epoch 248/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3464 - val_loss: 0.3433\n",
            "Epoch 249/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3452 - val_loss: 0.3423\n",
            "Epoch 250/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3439 - val_loss: 0.3413\n",
            "Epoch 251/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3432 - val_loss: 0.3404\n",
            "Epoch 252/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.3395\n",
            "Epoch 253/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3412 - val_loss: 0.3386\n",
            "Epoch 254/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3406 - val_loss: 0.3377\n",
            "Epoch 255/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.3368\n",
            "Epoch 256/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3382 - val_loss: 0.3360\n",
            "Epoch 257/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.3352\n",
            "Epoch 258/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3368 - val_loss: 0.3344\n",
            "Epoch 259/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3358 - val_loss: 0.3336\n",
            "Epoch 260/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3352 - val_loss: 0.3328\n",
            "Epoch 261/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3345 - val_loss: 0.3321\n",
            "Epoch 262/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.3313\n",
            "Epoch 263/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3336 - val_loss: 0.3306\n",
            "Epoch 264/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3324 - val_loss: 0.3299\n",
            "Epoch 265/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3316 - val_loss: 0.3292\n",
            "Epoch 266/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3311 - val_loss: 0.3285\n",
            "Epoch 267/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3304 - val_loss: 0.3279\n",
            "Epoch 268/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3294 - val_loss: 0.3272\n",
            "Epoch 269/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3290 - val_loss: 0.3266\n",
            "Epoch 270/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3281 - val_loss: 0.3260\n",
            "Epoch 271/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3279 - val_loss: 0.3254\n",
            "Epoch 272/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3271 - val_loss: 0.3248\n",
            "Epoch 273/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3263 - val_loss: 0.3242\n",
            "Epoch 274/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3258 - val_loss: 0.3236\n",
            "Epoch 275/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3252 - val_loss: 0.3231\n",
            "Epoch 276/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3249 - val_loss: 0.3225\n",
            "Epoch 277/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3245 - val_loss: 0.3220\n",
            "Epoch 278/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3235 - val_loss: 0.3215\n",
            "Epoch 279/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3230 - val_loss: 0.3210\n",
            "Epoch 280/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3223 - val_loss: 0.3205\n",
            "Epoch 281/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3226 - val_loss: 0.3200\n",
            "Epoch 282/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3218 - val_loss: 0.3195\n",
            "Epoch 283/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3211 - val_loss: 0.3190\n",
            "Epoch 284/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3204 - val_loss: 0.3185\n",
            "Epoch 285/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3200 - val_loss: 0.3181\n",
            "Epoch 286/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3197 - val_loss: 0.3176\n",
            "Epoch 287/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3195 - val_loss: 0.3172\n",
            "Epoch 288/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3190 - val_loss: 0.3168\n",
            "Epoch 289/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3182 - val_loss: 0.3164\n",
            "Epoch 290/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3182 - val_loss: 0.3160\n",
            "Epoch 291/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3174 - val_loss: 0.3156\n",
            "Epoch 292/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3170 - val_loss: 0.3152\n",
            "Epoch 293/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3168 - val_loss: 0.3148\n",
            "Epoch 294/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3162 - val_loss: 0.3144\n",
            "Epoch 295/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3158 - val_loss: 0.3140\n",
            "Epoch 296/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3155 - val_loss: 0.3137\n",
            "Epoch 297/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3151 - val_loss: 0.3133\n",
            "Epoch 298/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3151 - val_loss: 0.3129\n",
            "Epoch 299/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3141 - val_loss: 0.3126\n",
            "Epoch 300/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3139 - val_loss: 0.3123\n",
            "Epoch 301/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3138 - val_loss: 0.3119\n",
            "Epoch 302/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3133 - val_loss: 0.3116\n",
            "Epoch 303/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3131 - val_loss: 0.3113\n",
            "Epoch 304/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3129 - val_loss: 0.3110\n",
            "Epoch 305/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3122 - val_loss: 0.3106\n",
            "Epoch 306/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3122 - val_loss: 0.3103\n",
            "Epoch 307/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3120 - val_loss: 0.3100\n",
            "Epoch 308/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3114 - val_loss: 0.3097\n",
            "Epoch 309/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3113 - val_loss: 0.3095\n",
            "Epoch 310/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3107 - val_loss: 0.3092\n",
            "Epoch 311/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3106 - val_loss: 0.3089\n",
            "Epoch 312/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3102 - val_loss: 0.3086\n",
            "Epoch 313/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3099 - val_loss: 0.3083\n",
            "Epoch 314/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3097 - val_loss: 0.3081\n",
            "Epoch 315/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3093 - val_loss: 0.3078\n",
            "Epoch 316/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3092 - val_loss: 0.3076\n",
            "Epoch 317/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3091 - val_loss: 0.3073\n",
            "Epoch 318/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3083 - val_loss: 0.3071\n",
            "Epoch 319/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3082 - val_loss: 0.3068\n",
            "Epoch 320/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3080 - val_loss: 0.3066\n",
            "Epoch 321/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3079 - val_loss: 0.3063\n",
            "Epoch 322/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3077 - val_loss: 0.3061\n",
            "Epoch 323/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3074 - val_loss: 0.3059\n",
            "Epoch 324/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3071 - val_loss: 0.3057\n",
            "Epoch 325/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3069 - val_loss: 0.3054\n",
            "Epoch 326/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3068 - val_loss: 0.3052\n",
            "Epoch 327/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3066 - val_loss: 0.3050\n",
            "Epoch 328/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3064 - val_loss: 0.3048\n",
            "Epoch 329/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3064 - val_loss: 0.3046\n",
            "Epoch 330/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3059 - val_loss: 0.3044\n",
            "Epoch 331/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3055 - val_loss: 0.3042\n",
            "Epoch 332/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3053 - val_loss: 0.3040\n",
            "Epoch 333/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3052 - val_loss: 0.3038\n",
            "Epoch 334/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3051 - val_loss: 0.3036\n",
            "Epoch 335/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3047 - val_loss: 0.3034\n",
            "Epoch 336/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3046 - val_loss: 0.3032\n",
            "Epoch 337/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3046 - val_loss: 0.3030\n",
            "Epoch 338/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3042 - val_loss: 0.3028\n",
            "Epoch 339/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3041 - val_loss: 0.3027\n",
            "Epoch 340/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3038 - val_loss: 0.3025\n",
            "Epoch 341/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3038 - val_loss: 0.3023\n",
            "Epoch 342/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3037 - val_loss: 0.3021\n",
            "Epoch 343/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3035 - val_loss: 0.3020\n",
            "Epoch 344/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3031 - val_loss: 0.3018\n",
            "Epoch 345/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3032 - val_loss: 0.3016\n",
            "Epoch 346/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3027 - val_loss: 0.3015\n",
            "Epoch 347/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3024 - val_loss: 0.3013\n",
            "Epoch 348/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3027 - val_loss: 0.3011\n",
            "Epoch 349/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3022 - val_loss: 0.3010\n",
            "Epoch 350/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3023 - val_loss: 0.3008\n",
            "Epoch 351/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3019 - val_loss: 0.3007\n",
            "Epoch 352/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3019 - val_loss: 0.3005\n",
            "Epoch 353/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3019 - val_loss: 0.3004\n",
            "Epoch 354/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3015 - val_loss: 0.3002\n",
            "Epoch 355/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3016 - val_loss: 0.3001\n",
            "Epoch 356/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3013 - val_loss: 0.3000\n",
            "Epoch 357/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3009 - val_loss: 0.2998\n",
            "Epoch 358/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3012 - val_loss: 0.2997\n",
            "Epoch 359/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3007 - val_loss: 0.2995\n",
            "Epoch 360/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3007 - val_loss: 0.2994\n",
            "Epoch 361/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3005 - val_loss: 0.2993\n",
            "Epoch 362/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3006 - val_loss: 0.2991\n",
            "Epoch 363/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3004 - val_loss: 0.2990\n",
            "Epoch 364/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3001 - val_loss: 0.2989\n",
            "Epoch 365/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2999 - val_loss: 0.2987\n",
            "Epoch 366/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2998 - val_loss: 0.2986\n",
            "Epoch 367/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2999 - val_loss: 0.2985\n",
            "Epoch 368/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2995 - val_loss: 0.2984\n",
            "Epoch 369/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3000 - val_loss: 0.2982\n",
            "Epoch 370/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2995 - val_loss: 0.2981\n",
            "Epoch 371/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2993 - val_loss: 0.2980\n",
            "Epoch 372/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2988 - val_loss: 0.2979\n",
            "Epoch 373/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2993 - val_loss: 0.2978\n",
            "Epoch 374/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2988 - val_loss: 0.2977\n",
            "Epoch 375/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2983 - val_loss: 0.2975\n",
            "Epoch 376/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2985 - val_loss: 0.2974\n",
            "Epoch 377/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2988 - val_loss: 0.2973\n",
            "Epoch 378/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2982 - val_loss: 0.2972\n",
            "Epoch 379/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2983 - val_loss: 0.2971\n",
            "Epoch 380/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2981 - val_loss: 0.2970\n",
            "Epoch 381/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2981 - val_loss: 0.2969\n",
            "Epoch 382/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2976 - val_loss: 0.2968\n",
            "Epoch 383/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2981 - val_loss: 0.2967\n",
            "Epoch 384/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2975 - val_loss: 0.2966\n",
            "Epoch 385/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2977 - val_loss: 0.2965\n",
            "Epoch 386/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2977 - val_loss: 0.2964\n",
            "Epoch 387/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2972 - val_loss: 0.2963\n",
            "Epoch 388/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2974 - val_loss: 0.2962\n",
            "Epoch 389/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2978 - val_loss: 0.2961\n",
            "Epoch 390/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2971 - val_loss: 0.2960\n",
            "Epoch 391/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2976 - val_loss: 0.2959\n",
            "Epoch 392/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2969 - val_loss: 0.2958\n",
            "Epoch 393/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2965 - val_loss: 0.2957\n",
            "Epoch 394/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2966 - val_loss: 0.2956\n",
            "Epoch 395/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2966 - val_loss: 0.2955\n",
            "Epoch 396/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2967 - val_loss: 0.2954\n",
            "Epoch 397/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2963 - val_loss: 0.2953\n",
            "Epoch 398/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2966 - val_loss: 0.2953\n",
            "Epoch 399/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2967 - val_loss: 0.2952\n",
            "Epoch 400/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2964 - val_loss: 0.2951\n",
            "Epoch 401/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2964 - val_loss: 0.2950\n",
            "Epoch 402/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2961 - val_loss: 0.2949\n",
            "Epoch 403/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2961 - val_loss: 0.2948\n",
            "Epoch 404/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2953 - val_loss: 0.2947\n",
            "Epoch 405/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2960 - val_loss: 0.2947\n",
            "Epoch 406/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2956 - val_loss: 0.2946\n",
            "Epoch 407/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2956 - val_loss: 0.2945\n",
            "Epoch 408/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2950 - val_loss: 0.2944\n",
            "Epoch 409/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2955 - val_loss: 0.2943\n",
            "Epoch 410/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2954 - val_loss: 0.2943\n",
            "Epoch 411/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2955 - val_loss: 0.2942\n",
            "Epoch 412/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2951 - val_loss: 0.2941\n",
            "Epoch 413/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2950 - val_loss: 0.2940\n",
            "Epoch 414/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2951 - val_loss: 0.2939\n",
            "Epoch 415/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2946 - val_loss: 0.2939\n",
            "Epoch 416/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2945 - val_loss: 0.2938\n",
            "Epoch 417/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2949 - val_loss: 0.2937\n",
            "Epoch 418/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2947 - val_loss: 0.2936\n",
            "Epoch 419/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2949 - val_loss: 0.2936\n",
            "Epoch 420/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2945 - val_loss: 0.2935\n",
            "Epoch 421/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2949 - val_loss: 0.2934\n",
            "Epoch 422/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2947 - val_loss: 0.2934\n",
            "Epoch 423/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2945 - val_loss: 0.2933\n",
            "Epoch 424/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2944 - val_loss: 0.2932\n",
            "Epoch 425/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2946 - val_loss: 0.2932\n",
            "Epoch 426/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2944 - val_loss: 0.2931\n",
            "Epoch 427/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2943 - val_loss: 0.2930\n",
            "Epoch 428/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2941 - val_loss: 0.2929\n",
            "Epoch 429/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2942 - val_loss: 0.2929\n",
            "Epoch 430/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2939 - val_loss: 0.2928\n",
            "Epoch 431/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2939 - val_loss: 0.2928\n",
            "Epoch 432/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2937 - val_loss: 0.2927\n",
            "Epoch 433/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2940 - val_loss: 0.2926\n",
            "Epoch 434/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2935 - val_loss: 0.2926\n",
            "Epoch 435/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2935 - val_loss: 0.2925\n",
            "Epoch 436/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2935 - val_loss: 0.2924\n",
            "Epoch 437/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2937 - val_loss: 0.2924\n",
            "Epoch 438/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2934 - val_loss: 0.2923\n",
            "Epoch 439/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2934 - val_loss: 0.2922\n",
            "Epoch 440/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2933 - val_loss: 0.2922\n",
            "Epoch 441/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2930 - val_loss: 0.2921\n",
            "Epoch 442/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2929 - val_loss: 0.2921\n",
            "Epoch 443/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2928 - val_loss: 0.2920\n",
            "Epoch 444/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2931 - val_loss: 0.2919\n",
            "Epoch 445/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2930 - val_loss: 0.2919\n",
            "Epoch 446/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2926 - val_loss: 0.2918\n",
            "Epoch 447/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2926 - val_loss: 0.2918\n",
            "Epoch 448/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2928 - val_loss: 0.2917\n",
            "Epoch 449/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2928 - val_loss: 0.2917\n",
            "Epoch 450/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2926 - val_loss: 0.2916\n",
            "Epoch 451/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2925 - val_loss: 0.2915\n",
            "Epoch 452/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2926 - val_loss: 0.2915\n",
            "Epoch 453/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2927 - val_loss: 0.2914\n",
            "Epoch 454/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2922 - val_loss: 0.2914\n",
            "Epoch 455/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2924 - val_loss: 0.2913\n",
            "Epoch 456/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2927 - val_loss: 0.2913\n",
            "Epoch 457/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2920 - val_loss: 0.2912\n",
            "Epoch 458/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2923 - val_loss: 0.2912\n",
            "Epoch 459/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2921 - val_loss: 0.2911\n",
            "Epoch 460/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2920 - val_loss: 0.2911\n",
            "Epoch 461/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2924 - val_loss: 0.2910\n",
            "Epoch 462/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2916 - val_loss: 0.2910\n",
            "Epoch 463/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2916 - val_loss: 0.2909\n",
            "Epoch 464/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2919 - val_loss: 0.2909\n",
            "Epoch 465/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2918 - val_loss: 0.2908\n",
            "Epoch 466/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2915 - val_loss: 0.2908\n",
            "Epoch 467/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2917 - val_loss: 0.2907\n",
            "Epoch 468/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2916 - val_loss: 0.2907\n",
            "Epoch 469/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2918 - val_loss: 0.2906\n",
            "Epoch 470/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2916 - val_loss: 0.2906\n",
            "Epoch 471/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2917 - val_loss: 0.2905\n",
            "Epoch 472/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2915 - val_loss: 0.2905\n",
            "Epoch 473/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2915 - val_loss: 0.2904\n",
            "Epoch 474/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2915 - val_loss: 0.2904\n",
            "Epoch 475/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2914 - val_loss: 0.2903\n",
            "Epoch 476/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2911 - val_loss: 0.2903\n",
            "Epoch 477/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2912 - val_loss: 0.2902\n",
            "Epoch 478/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2914 - val_loss: 0.2902\n",
            "Epoch 479/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2909 - val_loss: 0.2901\n",
            "Epoch 480/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2916 - val_loss: 0.2901\n",
            "Epoch 481/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2908 - val_loss: 0.2901\n",
            "Epoch 482/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2910 - val_loss: 0.2900\n",
            "Epoch 483/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2912 - val_loss: 0.2900\n",
            "Epoch 484/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2903 - val_loss: 0.2899\n",
            "Epoch 485/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2904 - val_loss: 0.2899\n",
            "Epoch 486/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2906 - val_loss: 0.2898\n",
            "Epoch 487/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2906 - val_loss: 0.2898\n",
            "Epoch 488/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2909 - val_loss: 0.2897\n",
            "Epoch 489/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2909 - val_loss: 0.2897\n",
            "Epoch 490/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2908 - val_loss: 0.2897\n",
            "Epoch 491/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2907 - val_loss: 0.2896\n",
            "Epoch 492/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2904 - val_loss: 0.2896\n",
            "Epoch 493/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2905 - val_loss: 0.2895\n",
            "Epoch 494/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2904 - val_loss: 0.2895\n",
            "Epoch 495/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2904 - val_loss: 0.2895\n",
            "Epoch 496/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2906 - val_loss: 0.2894\n",
            "Epoch 497/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2902 - val_loss: 0.2894\n",
            "Epoch 498/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2906 - val_loss: 0.2893\n",
            "Epoch 499/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2904 - val_loss: 0.2893\n",
            "Epoch 500/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2901 - val_loss: 0.2893\n",
            "Epoch 501/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2900 - val_loss: 0.2892\n",
            "Epoch 502/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2901 - val_loss: 0.2892\n",
            "Epoch 503/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2902 - val_loss: 0.2891\n",
            "Epoch 504/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2904 - val_loss: 0.2891\n",
            "Epoch 505/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2899 - val_loss: 0.2891\n",
            "Epoch 506/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2901 - val_loss: 0.2890\n",
            "Epoch 507/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2899 - val_loss: 0.2890\n",
            "Epoch 508/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2897 - val_loss: 0.2889\n",
            "Epoch 509/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2905 - val_loss: 0.2889\n",
            "Epoch 510/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2899 - val_loss: 0.2889\n",
            "Epoch 511/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2899 - val_loss: 0.2888\n",
            "Epoch 512/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2896 - val_loss: 0.2888\n",
            "Epoch 513/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2898 - val_loss: 0.2888\n",
            "Epoch 514/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2896 - val_loss: 0.2887\n",
            "Epoch 515/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2896 - val_loss: 0.2887\n",
            "Epoch 516/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2897 - val_loss: 0.2886\n",
            "Epoch 517/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2894 - val_loss: 0.2886\n",
            "Epoch 518/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2895 - val_loss: 0.2886\n",
            "Epoch 519/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2895 - val_loss: 0.2885\n",
            "Epoch 520/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2898 - val_loss: 0.2885\n",
            "Epoch 521/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2891 - val_loss: 0.2885\n",
            "Epoch 522/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2896 - val_loss: 0.2884\n",
            "Epoch 523/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2895 - val_loss: 0.2884\n",
            "Epoch 524/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2892 - val_loss: 0.2884\n",
            "Epoch 525/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2891 - val_loss: 0.2883\n",
            "Epoch 526/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2896 - val_loss: 0.2883\n",
            "Epoch 527/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2893 - val_loss: 0.2883\n",
            "Epoch 528/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2892 - val_loss: 0.2882\n",
            "Epoch 529/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2890 - val_loss: 0.2882\n",
            "Epoch 530/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2891 - val_loss: 0.2882\n",
            "Epoch 531/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2892 - val_loss: 0.2881\n",
            "Epoch 532/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2889 - val_loss: 0.2881\n",
            "Epoch 533/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2888 - val_loss: 0.2881\n",
            "Epoch 534/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2893 - val_loss: 0.2880\n",
            "Epoch 535/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2889 - val_loss: 0.2880\n",
            "Epoch 536/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2891 - val_loss: 0.2880\n",
            "Epoch 537/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2889 - val_loss: 0.2879\n",
            "Epoch 538/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2888 - val_loss: 0.2879\n",
            "Epoch 539/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2889 - val_loss: 0.2879\n",
            "Epoch 540/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2886 - val_loss: 0.2878\n",
            "Epoch 541/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2889 - val_loss: 0.2878\n",
            "Epoch 542/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2888 - val_loss: 0.2878\n",
            "Epoch 543/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2889 - val_loss: 0.2877\n",
            "Epoch 544/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2883 - val_loss: 0.2877\n",
            "Epoch 545/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2888 - val_loss: 0.2877\n",
            "Epoch 546/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2889 - val_loss: 0.2876\n",
            "Epoch 547/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2886 - val_loss: 0.2876\n",
            "Epoch 548/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2885 - val_loss: 0.2876\n",
            "Epoch 549/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2882 - val_loss: 0.2875\n",
            "Epoch 550/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2886 - val_loss: 0.2875\n",
            "Epoch 551/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2885 - val_loss: 0.2875\n",
            "Epoch 552/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2881 - val_loss: 0.2875\n",
            "Epoch 553/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2884 - val_loss: 0.2874\n",
            "Epoch 554/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2885 - val_loss: 0.2874\n",
            "Epoch 555/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2880 - val_loss: 0.2874\n",
            "Epoch 556/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2881 - val_loss: 0.2873\n",
            "Epoch 557/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2884 - val_loss: 0.2873\n",
            "Epoch 558/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2883 - val_loss: 0.2873\n",
            "Epoch 559/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2888 - val_loss: 0.2872\n",
            "Epoch 560/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2882 - val_loss: 0.2872\n",
            "Epoch 561/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2882 - val_loss: 0.2872\n",
            "Epoch 562/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2885 - val_loss: 0.2872\n",
            "Epoch 563/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2886 - val_loss: 0.2871\n",
            "Epoch 564/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2876 - val_loss: 0.2871\n",
            "Epoch 565/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2882 - val_loss: 0.2871\n",
            "Epoch 566/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2881 - val_loss: 0.2870\n",
            "Epoch 567/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2880 - val_loss: 0.2870\n",
            "Epoch 568/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2880 - val_loss: 0.2870\n",
            "Epoch 569/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2877 - val_loss: 0.2870\n",
            "Epoch 570/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2878 - val_loss: 0.2869\n",
            "Epoch 571/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2876 - val_loss: 0.2869\n",
            "Epoch 572/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2876 - val_loss: 0.2869\n",
            "Epoch 573/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2878 - val_loss: 0.2869\n",
            "Epoch 574/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2875 - val_loss: 0.2868\n",
            "Epoch 575/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2876 - val_loss: 0.2868\n",
            "Epoch 576/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2876 - val_loss: 0.2868\n",
            "Epoch 577/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2872 - val_loss: 0.2867\n",
            "Epoch 578/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2874 - val_loss: 0.2867\n",
            "Epoch 579/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2878 - val_loss: 0.2867\n",
            "Epoch 580/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2874 - val_loss: 0.2867\n",
            "Epoch 581/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2878 - val_loss: 0.2866\n",
            "Epoch 582/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2877 - val_loss: 0.2866\n",
            "Epoch 583/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2880 - val_loss: 0.2866\n",
            "Epoch 584/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2877 - val_loss: 0.2866\n",
            "Epoch 585/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2876 - val_loss: 0.2865\n",
            "Epoch 586/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2874 - val_loss: 0.2865\n",
            "Epoch 587/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2870 - val_loss: 0.2865\n",
            "Epoch 588/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2875 - val_loss: 0.2865\n",
            "Epoch 589/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2873 - val_loss: 0.2864\n",
            "Epoch 590/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2872 - val_loss: 0.2864\n",
            "Epoch 591/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2874 - val_loss: 0.2864\n",
            "Epoch 592/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2872 - val_loss: 0.2864\n",
            "Epoch 593/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2867 - val_loss: 0.2863\n",
            "Epoch 594/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2869 - val_loss: 0.2863\n",
            "Epoch 595/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2873 - val_loss: 0.2863\n",
            "Epoch 596/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2872 - val_loss: 0.2863\n",
            "Epoch 597/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2872 - val_loss: 0.2862\n",
            "Epoch 598/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2873 - val_loss: 0.2862\n",
            "Epoch 599/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2871 - val_loss: 0.2862\n",
            "Epoch 600/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2866 - val_loss: 0.2862\n",
            "Epoch 601/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2868 - val_loss: 0.2861\n",
            "Epoch 602/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2867 - val_loss: 0.2861\n",
            "Epoch 603/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2870 - val_loss: 0.2861\n",
            "Epoch 604/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2872 - val_loss: 0.2861\n",
            "Epoch 605/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2870 - val_loss: 0.2860\n",
            "Epoch 606/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2875 - val_loss: 0.2860\n",
            "Epoch 607/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2868 - val_loss: 0.2860\n",
            "Epoch 608/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2868 - val_loss: 0.2860\n",
            "Epoch 609/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2865 - val_loss: 0.2859\n",
            "Epoch 610/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2867 - val_loss: 0.2859\n",
            "Epoch 611/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2866 - val_loss: 0.2859\n",
            "Epoch 612/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2864 - val_loss: 0.2859\n",
            "Epoch 613/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2869 - val_loss: 0.2858\n",
            "Epoch 614/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2870 - val_loss: 0.2858\n",
            "Epoch 615/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2869 - val_loss: 0.2858\n",
            "Epoch 616/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2869 - val_loss: 0.2858\n",
            "Epoch 617/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2868 - val_loss: 0.2857\n",
            "Epoch 618/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2863 - val_loss: 0.2857\n",
            "Epoch 619/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2868 - val_loss: 0.2857\n",
            "Epoch 620/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2865 - val_loss: 0.2857\n",
            "Epoch 621/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2863 - val_loss: 0.2857\n",
            "Epoch 622/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2865 - val_loss: 0.2856\n",
            "Epoch 623/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2870 - val_loss: 0.2856\n",
            "Epoch 624/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2866 - val_loss: 0.2856\n",
            "Epoch 625/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2867 - val_loss: 0.2856\n",
            "Epoch 626/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2868 - val_loss: 0.2855\n",
            "Epoch 627/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2866 - val_loss: 0.2855\n",
            "Epoch 628/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2861 - val_loss: 0.2855\n",
            "Epoch 629/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2864 - val_loss: 0.2855\n",
            "Epoch 630/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2865 - val_loss: 0.2855\n",
            "Epoch 631/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2863 - val_loss: 0.2854\n",
            "Epoch 632/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2864 - val_loss: 0.2854\n",
            "Epoch 633/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2863 - val_loss: 0.2854\n",
            "Epoch 634/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2865 - val_loss: 0.2854\n",
            "Epoch 635/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2867 - val_loss: 0.2853\n",
            "Epoch 636/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2861 - val_loss: 0.2853\n",
            "Epoch 637/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2861 - val_loss: 0.2853\n",
            "Epoch 638/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2863 - val_loss: 0.2853\n",
            "Epoch 639/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2860 - val_loss: 0.2853\n",
            "Epoch 640/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2862 - val_loss: 0.2852\n",
            "Epoch 641/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2862 - val_loss: 0.2852\n",
            "Epoch 642/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2862 - val_loss: 0.2852\n",
            "Epoch 643/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2862 - val_loss: 0.2852\n",
            "Epoch 644/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2857 - val_loss: 0.2852\n",
            "Epoch 645/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2857 - val_loss: 0.2851\n",
            "Epoch 646/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2859 - val_loss: 0.2851\n",
            "Epoch 647/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2861 - val_loss: 0.2851\n",
            "Epoch 648/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2857 - val_loss: 0.2851\n",
            "Epoch 649/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2861 - val_loss: 0.2850\n",
            "Epoch 650/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2858 - val_loss: 0.2850\n",
            "Epoch 651/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2856 - val_loss: 0.2850\n",
            "Epoch 652/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2858 - val_loss: 0.2850\n",
            "Epoch 653/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2858 - val_loss: 0.2850\n",
            "Epoch 654/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2856 - val_loss: 0.2849\n",
            "Epoch 655/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2854 - val_loss: 0.2849\n",
            "Epoch 656/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2859 - val_loss: 0.2849\n",
            "Epoch 657/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2855 - val_loss: 0.2849\n",
            "Epoch 658/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2855 - val_loss: 0.2849\n",
            "Epoch 659/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2856 - val_loss: 0.2848\n",
            "Epoch 660/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2856 - val_loss: 0.2848\n",
            "Epoch 661/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2855 - val_loss: 0.2848\n",
            "Epoch 662/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2857 - val_loss: 0.2848\n",
            "Epoch 663/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2855 - val_loss: 0.2848\n",
            "Epoch 664/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2854 - val_loss: 0.2847\n",
            "Epoch 665/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2856 - val_loss: 0.2847\n",
            "Epoch 666/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2853 - val_loss: 0.2847\n",
            "Epoch 667/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2856 - val_loss: 0.2847\n",
            "Epoch 668/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2860 - val_loss: 0.2847\n",
            "Epoch 669/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2856 - val_loss: 0.2846\n",
            "Epoch 670/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2855 - val_loss: 0.2846\n",
            "Epoch 671/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2857 - val_loss: 0.2846\n",
            "Epoch 672/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2853 - val_loss: 0.2846\n",
            "Epoch 673/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2854 - val_loss: 0.2846\n",
            "Epoch 674/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2854 - val_loss: 0.2845\n",
            "Epoch 675/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.2845\n",
            "Epoch 676/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2857 - val_loss: 0.2845\n",
            "Epoch 677/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2852 - val_loss: 0.2845\n",
            "Epoch 678/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2851 - val_loss: 0.2845\n",
            "Epoch 679/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2850 - val_loss: 0.2844\n",
            "Epoch 680/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2850 - val_loss: 0.2844\n",
            "Epoch 681/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.2844\n",
            "Epoch 682/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2848 - val_loss: 0.2844\n",
            "Epoch 683/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2851 - val_loss: 0.2844\n",
            "Epoch 684/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2850 - val_loss: 0.2844\n",
            "Epoch 685/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.2843\n",
            "Epoch 686/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2850 - val_loss: 0.2843\n",
            "Epoch 687/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2850 - val_loss: 0.2843\n",
            "Epoch 688/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.2843\n",
            "Epoch 689/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2851 - val_loss: 0.2843\n",
            "Epoch 690/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2847 - val_loss: 0.2842\n",
            "Epoch 691/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.2842\n",
            "Epoch 692/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2850 - val_loss: 0.2842\n",
            "Epoch 693/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2847 - val_loss: 0.2842\n",
            "Epoch 694/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2851 - val_loss: 0.2842\n",
            "Epoch 695/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.2841\n",
            "Epoch 696/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2848 - val_loss: 0.2841\n",
            "Epoch 697/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2845 - val_loss: 0.2841\n",
            "Epoch 698/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.2841\n",
            "Epoch 699/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.2841\n",
            "Epoch 700/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2852 - val_loss: 0.2841\n",
            "Epoch 701/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2845 - val_loss: 0.2840\n",
            "Epoch 702/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2852 - val_loss: 0.2840\n",
            "Epoch 703/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2848 - val_loss: 0.2840\n",
            "Epoch 704/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2851 - val_loss: 0.2840\n",
            "Epoch 705/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2845 - val_loss: 0.2840\n",
            "Epoch 706/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.2839\n",
            "Epoch 707/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2848 - val_loss: 0.2839\n",
            "Epoch 708/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2848 - val_loss: 0.2839\n",
            "Epoch 709/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.2839\n",
            "Epoch 710/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.2839\n",
            "Epoch 711/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2847 - val_loss: 0.2839\n",
            "Epoch 712/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.2838\n",
            "Epoch 713/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2847 - val_loss: 0.2838\n",
            "Epoch 714/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2846 - val_loss: 0.2838\n",
            "Epoch 715/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2848 - val_loss: 0.2838\n",
            "Epoch 716/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2847 - val_loss: 0.2838\n",
            "Epoch 717/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2846 - val_loss: 0.2837\n",
            "Epoch 718/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2847 - val_loss: 0.2837\n",
            "Epoch 719/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2846 - val_loss: 0.2837\n",
            "Epoch 720/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2844 - val_loss: 0.2837\n",
            "Epoch 721/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2846 - val_loss: 0.2837\n",
            "Epoch 722/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2845 - val_loss: 0.2837\n",
            "Epoch 723/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2846 - val_loss: 0.2836\n",
            "Epoch 724/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2845 - val_loss: 0.2836\n",
            "Epoch 725/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2845 - val_loss: 0.2836\n",
            "Epoch 726/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2844 - val_loss: 0.2836\n",
            "Epoch 727/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2844 - val_loss: 0.2836\n",
            "Epoch 728/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2846 - val_loss: 0.2836\n",
            "Epoch 729/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.2835\n",
            "Epoch 730/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2844 - val_loss: 0.2835\n",
            "Epoch 731/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2838 - val_loss: 0.2835\n",
            "Epoch 732/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2845 - val_loss: 0.2835\n",
            "Epoch 733/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.2835\n",
            "Epoch 734/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.2835\n",
            "Epoch 735/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.2834\n",
            "Epoch 736/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2840 - val_loss: 0.2834\n",
            "Epoch 737/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2841 - val_loss: 0.2834\n",
            "Epoch 738/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2840 - val_loss: 0.2834\n",
            "Epoch 739/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.2834\n",
            "Epoch 740/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2841 - val_loss: 0.2834\n",
            "Epoch 741/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2844 - val_loss: 0.2833\n",
            "Epoch 742/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2844 - val_loss: 0.2833\n",
            "Epoch 743/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2843 - val_loss: 0.2833\n",
            "Epoch 744/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.2833\n",
            "Epoch 745/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2840 - val_loss: 0.2833\n",
            "Epoch 746/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.2833\n",
            "Epoch 747/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.2832\n",
            "Epoch 748/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2840 - val_loss: 0.2832\n",
            "Epoch 749/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2841 - val_loss: 0.2832\n",
            "Epoch 750/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.2832\n",
            "Epoch 751/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2840 - val_loss: 0.2832\n",
            "Epoch 752/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2840 - val_loss: 0.2832\n",
            "Epoch 753/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2839 - val_loss: 0.2831\n",
            "Epoch 754/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.2831\n",
            "Epoch 755/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2832 - val_loss: 0.2831\n",
            "Epoch 756/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.2831\n",
            "Epoch 757/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2837 - val_loss: 0.2831\n",
            "Epoch 758/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2840 - val_loss: 0.2831\n",
            "Epoch 759/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.2830\n",
            "Epoch 760/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.2830\n",
            "Epoch 761/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2839 - val_loss: 0.2830\n",
            "Epoch 762/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2841 - val_loss: 0.2830\n",
            "Epoch 763/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.2830\n",
            "Epoch 764/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2838 - val_loss: 0.2830\n",
            "Epoch 765/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2841 - val_loss: 0.2829\n",
            "Epoch 766/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2839 - val_loss: 0.2829\n",
            "Epoch 767/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.2829\n",
            "Epoch 768/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.2829\n",
            "Epoch 769/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2833 - val_loss: 0.2829\n",
            "Epoch 770/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2840 - val_loss: 0.2829\n",
            "Epoch 771/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2837 - val_loss: 0.2828\n",
            "Epoch 772/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2837 - val_loss: 0.2828\n",
            "Epoch 773/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2838 - val_loss: 0.2828\n",
            "Epoch 774/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2837 - val_loss: 0.2828\n",
            "Epoch 775/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.2828\n",
            "Epoch 776/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.2828\n",
            "Epoch 777/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2836 - val_loss: 0.2828\n",
            "Epoch 778/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.2827\n",
            "Epoch 779/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2831 - val_loss: 0.2827\n",
            "Epoch 780/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2838 - val_loss: 0.2827\n",
            "Epoch 781/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.2827\n",
            "Epoch 782/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.2827\n",
            "Epoch 783/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2833 - val_loss: 0.2827\n",
            "Epoch 784/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.2826\n",
            "Epoch 785/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.2826\n",
            "Epoch 786/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2829 - val_loss: 0.2826\n",
            "Epoch 787/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.2826\n",
            "Epoch 788/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2833 - val_loss: 0.2826\n",
            "Epoch 789/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2835 - val_loss: 0.2826\n",
            "Epoch 790/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2833 - val_loss: 0.2825\n",
            "Epoch 791/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2833 - val_loss: 0.2825\n",
            "Epoch 792/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2833 - val_loss: 0.2825\n",
            "Epoch 793/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2835 - val_loss: 0.2825\n",
            "Epoch 794/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2832 - val_loss: 0.2825\n",
            "Epoch 795/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2835 - val_loss: 0.2825\n",
            "Epoch 796/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.2825\n",
            "Epoch 797/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2833 - val_loss: 0.2824\n",
            "Epoch 798/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2832 - val_loss: 0.2824\n",
            "Epoch 799/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.2824\n",
            "Epoch 800/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2830 - val_loss: 0.2824\n",
            "Epoch 801/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2833 - val_loss: 0.2824\n",
            "Epoch 802/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2832 - val_loss: 0.2824\n",
            "Epoch 803/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2830 - val_loss: 0.2823\n",
            "Epoch 804/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2831 - val_loss: 0.2823\n",
            "Epoch 805/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2829 - val_loss: 0.2823\n",
            "Epoch 806/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2830 - val_loss: 0.2823\n",
            "Epoch 807/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2831 - val_loss: 0.2823\n",
            "Epoch 808/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2831 - val_loss: 0.2823\n",
            "Epoch 809/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2833 - val_loss: 0.2823\n",
            "Epoch 810/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2829 - val_loss: 0.2822\n",
            "Epoch 811/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2833 - val_loss: 0.2822\n",
            "Epoch 812/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2828 - val_loss: 0.2822\n",
            "Epoch 813/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2830 - val_loss: 0.2822\n",
            "Epoch 814/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2833 - val_loss: 0.2822\n",
            "Epoch 815/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2828 - val_loss: 0.2822\n",
            "Epoch 816/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2828 - val_loss: 0.2821\n",
            "Epoch 817/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2828 - val_loss: 0.2821\n",
            "Epoch 818/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2828 - val_loss: 0.2821\n",
            "Epoch 819/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2831 - val_loss: 0.2821\n",
            "Epoch 820/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2826 - val_loss: 0.2821\n",
            "Epoch 821/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2827 - val_loss: 0.2821\n",
            "Epoch 822/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2827 - val_loss: 0.2821\n",
            "Epoch 823/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2827 - val_loss: 0.2820\n",
            "Epoch 824/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2830 - val_loss: 0.2820\n",
            "Epoch 825/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.2820\n",
            "Epoch 826/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.2820\n",
            "Epoch 827/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2831 - val_loss: 0.2820\n",
            "Epoch 828/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2826 - val_loss: 0.2820\n",
            "Epoch 829/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2828 - val_loss: 0.2820\n",
            "Epoch 830/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2830 - val_loss: 0.2819\n",
            "Epoch 831/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.2819\n",
            "Epoch 832/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2829 - val_loss: 0.2819\n",
            "Epoch 833/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.2819\n",
            "Epoch 834/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.2819\n",
            "Epoch 835/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.2819\n",
            "Epoch 836/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.2819\n",
            "Epoch 837/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2822 - val_loss: 0.2818\n",
            "Epoch 838/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2827 - val_loss: 0.2818\n",
            "Epoch 839/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2823 - val_loss: 0.2818\n",
            "Epoch 840/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2822 - val_loss: 0.2818\n",
            "Epoch 841/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.2818\n",
            "Epoch 842/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2822 - val_loss: 0.2818\n",
            "Epoch 843/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2824 - val_loss: 0.2817\n",
            "Epoch 844/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2823 - val_loss: 0.2817\n",
            "Epoch 845/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.2817\n",
            "Epoch 846/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2824 - val_loss: 0.2817\n",
            "Epoch 847/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2827 - val_loss: 0.2817\n",
            "Epoch 848/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2828 - val_loss: 0.2817\n",
            "Epoch 849/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2821 - val_loss: 0.2817\n",
            "Epoch 850/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2828 - val_loss: 0.2816\n",
            "Epoch 851/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2824 - val_loss: 0.2816\n",
            "Epoch 852/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.2816\n",
            "Epoch 853/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2824 - val_loss: 0.2816\n",
            "Epoch 854/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2821 - val_loss: 0.2816\n",
            "Epoch 855/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2827 - val_loss: 0.2816\n",
            "Epoch 856/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2824 - val_loss: 0.2816\n",
            "Epoch 857/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2826 - val_loss: 0.2815\n",
            "Epoch 858/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.2815\n",
            "Epoch 859/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2822 - val_loss: 0.2815\n",
            "Epoch 860/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2826 - val_loss: 0.2815\n",
            "Epoch 861/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2824 - val_loss: 0.2815\n",
            "Epoch 862/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2823 - val_loss: 0.2815\n",
            "Epoch 863/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2824 - val_loss: 0.2815\n",
            "Epoch 864/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2817 - val_loss: 0.2814\n",
            "Epoch 865/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.2814\n",
            "Epoch 866/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2822 - val_loss: 0.2814\n",
            "Epoch 867/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.2814\n",
            "Epoch 868/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2827 - val_loss: 0.2814\n",
            "Epoch 869/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2822 - val_loss: 0.2814\n",
            "Epoch 870/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2823 - val_loss: 0.2814\n",
            "Epoch 871/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.2813\n",
            "Epoch 872/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2820 - val_loss: 0.2813\n",
            "Epoch 873/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.2813\n",
            "Epoch 874/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.2813\n",
            "Epoch 875/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2820 - val_loss: 0.2813\n",
            "Epoch 876/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2817 - val_loss: 0.2813\n",
            "Epoch 877/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2818 - val_loss: 0.2813\n",
            "Epoch 878/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2818 - val_loss: 0.2812\n",
            "Epoch 879/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2824 - val_loss: 0.2812\n",
            "Epoch 880/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.2812\n",
            "Epoch 881/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2822 - val_loss: 0.2812\n",
            "Epoch 882/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2821 - val_loss: 0.2812\n",
            "Epoch 883/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2821 - val_loss: 0.2812\n",
            "Epoch 884/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2822 - val_loss: 0.2812\n",
            "Epoch 885/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2818 - val_loss: 0.2811\n",
            "Epoch 886/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2820 - val_loss: 0.2811\n",
            "Epoch 887/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2822 - val_loss: 0.2811\n",
            "Epoch 888/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2820 - val_loss: 0.2811\n",
            "Epoch 889/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2820 - val_loss: 0.2811\n",
            "Epoch 890/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2821 - val_loss: 0.2811\n",
            "Epoch 891/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.2811\n",
            "Epoch 892/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2820 - val_loss: 0.2810\n",
            "Epoch 893/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2818 - val_loss: 0.2810\n",
            "Epoch 894/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2823 - val_loss: 0.2810\n",
            "Epoch 895/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.2810\n",
            "Epoch 896/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2818 - val_loss: 0.2810\n",
            "Epoch 897/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.2810\n",
            "Epoch 898/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.2810\n",
            "Epoch 899/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2814 - val_loss: 0.2809\n",
            "Epoch 900/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2817 - val_loss: 0.2809\n",
            "Epoch 901/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2816 - val_loss: 0.2809\n",
            "Epoch 902/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2823 - val_loss: 0.2809\n",
            "Epoch 903/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2814 - val_loss: 0.2809\n",
            "Epoch 904/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2820 - val_loss: 0.2809\n",
            "Epoch 905/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2818 - val_loss: 0.2809\n",
            "Epoch 906/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2817 - val_loss: 0.2808\n",
            "Epoch 907/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.2808\n",
            "Epoch 908/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.2808\n",
            "Epoch 909/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2816 - val_loss: 0.2808\n",
            "Epoch 910/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2813 - val_loss: 0.2808\n",
            "Epoch 911/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2815 - val_loss: 0.2808\n",
            "Epoch 912/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2816 - val_loss: 0.2808\n",
            "Epoch 913/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2810 - val_loss: 0.2807\n",
            "Epoch 914/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2815 - val_loss: 0.2807\n",
            "Epoch 915/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2814 - val_loss: 0.2807\n",
            "Epoch 916/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2815 - val_loss: 0.2807\n",
            "Epoch 917/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2815 - val_loss: 0.2807\n",
            "Epoch 918/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2816 - val_loss: 0.2807\n",
            "Epoch 919/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2814 - val_loss: 0.2807\n",
            "Epoch 920/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2814 - val_loss: 0.2806\n",
            "Epoch 921/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2814 - val_loss: 0.2806\n",
            "Epoch 922/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2812 - val_loss: 0.2806\n",
            "Epoch 923/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2815 - val_loss: 0.2806\n",
            "Epoch 924/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2818 - val_loss: 0.2806\n",
            "Epoch 925/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2817 - val_loss: 0.2806\n",
            "Epoch 926/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2812 - val_loss: 0.2806\n",
            "Epoch 927/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2809 - val_loss: 0.2806\n",
            "Epoch 928/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2813 - val_loss: 0.2805\n",
            "Epoch 929/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2809 - val_loss: 0.2805\n",
            "Epoch 930/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2809 - val_loss: 0.2805\n",
            "Epoch 931/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2812 - val_loss: 0.2805\n",
            "Epoch 932/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2813 - val_loss: 0.2805\n",
            "Epoch 933/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2811 - val_loss: 0.2805\n",
            "Epoch 934/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2811 - val_loss: 0.2805\n",
            "Epoch 935/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2812 - val_loss: 0.2804\n",
            "Epoch 936/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2813 - val_loss: 0.2804\n",
            "Epoch 937/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2812 - val_loss: 0.2804\n",
            "Epoch 938/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2811 - val_loss: 0.2804\n",
            "Epoch 939/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2810 - val_loss: 0.2804\n",
            "Epoch 940/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2813 - val_loss: 0.2804\n",
            "Epoch 941/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2811 - val_loss: 0.2804\n",
            "Epoch 942/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2813 - val_loss: 0.2803\n",
            "Epoch 943/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2807 - val_loss: 0.2803\n",
            "Epoch 944/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2813 - val_loss: 0.2803\n",
            "Epoch 945/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2810 - val_loss: 0.2803\n",
            "Epoch 946/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2815 - val_loss: 0.2803\n",
            "Epoch 947/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2809 - val_loss: 0.2803\n",
            "Epoch 948/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2812 - val_loss: 0.2803\n",
            "Epoch 949/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2810 - val_loss: 0.2802\n",
            "Epoch 950/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2807 - val_loss: 0.2802\n",
            "Epoch 951/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2807 - val_loss: 0.2802\n",
            "Epoch 952/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2806 - val_loss: 0.2802\n",
            "Epoch 953/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2806 - val_loss: 0.2802\n",
            "Epoch 954/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2806 - val_loss: 0.2802\n",
            "Epoch 955/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2809 - val_loss: 0.2802\n",
            "Epoch 956/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2809 - val_loss: 0.2802\n",
            "Epoch 957/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2810 - val_loss: 0.2801\n",
            "Epoch 958/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2808 - val_loss: 0.2801\n",
            "Epoch 959/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2810 - val_loss: 0.2801\n",
            "Epoch 960/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2810 - val_loss: 0.2801\n",
            "Epoch 961/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2808 - val_loss: 0.2801\n",
            "Epoch 962/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2805 - val_loss: 0.2801\n",
            "Epoch 963/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2810 - val_loss: 0.2801\n",
            "Epoch 964/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2810 - val_loss: 0.2800\n",
            "Epoch 965/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2809 - val_loss: 0.2800\n",
            "Epoch 966/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2807 - val_loss: 0.2800\n",
            "Epoch 967/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2806 - val_loss: 0.2800\n",
            "Epoch 968/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2809 - val_loss: 0.2800\n",
            "Epoch 969/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2805 - val_loss: 0.2800\n",
            "Epoch 970/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2811 - val_loss: 0.2800\n",
            "Epoch 971/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2807 - val_loss: 0.2799\n",
            "Epoch 972/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2803 - val_loss: 0.2799\n",
            "Epoch 973/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2806 - val_loss: 0.2799\n",
            "Epoch 974/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2806 - val_loss: 0.2799\n",
            "Epoch 975/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2804 - val_loss: 0.2799\n",
            "Epoch 976/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2806 - val_loss: 0.2799\n",
            "Epoch 977/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2809 - val_loss: 0.2799\n",
            "Epoch 978/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2808 - val_loss: 0.2798\n",
            "Epoch 979/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2806 - val_loss: 0.2798\n",
            "Epoch 980/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2801 - val_loss: 0.2798\n",
            "Epoch 981/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2809 - val_loss: 0.2798\n",
            "Epoch 982/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2806 - val_loss: 0.2798\n",
            "Epoch 983/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2805 - val_loss: 0.2798\n",
            "Epoch 984/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2805 - val_loss: 0.2798\n",
            "Epoch 985/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2804 - val_loss: 0.2798\n",
            "Epoch 986/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2802 - val_loss: 0.2797\n",
            "Epoch 987/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2805 - val_loss: 0.2797\n",
            "Epoch 988/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2803 - val_loss: 0.2797\n",
            "Epoch 989/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2805 - val_loss: 0.2797\n",
            "Epoch 990/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2801 - val_loss: 0.2797\n",
            "Epoch 991/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2804 - val_loss: 0.2797\n",
            "Epoch 992/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2802 - val_loss: 0.2797\n",
            "Epoch 993/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2803 - val_loss: 0.2796\n",
            "Epoch 994/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2803 - val_loss: 0.2796\n",
            "Epoch 995/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2801 - val_loss: 0.2796\n",
            "Epoch 996/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2805 - val_loss: 0.2796\n",
            "Epoch 997/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2803 - val_loss: 0.2796\n",
            "Epoch 998/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2805 - val_loss: 0.2796\n",
            "Epoch 999/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2802 - val_loss: 0.2796\n",
            "Epoch 1000/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2800 - val_loss: 0.2795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f97702a6450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSFDi1gZ6NhN"
      },
      "source": [
        "### 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbPgh-Bo6KWL"
      },
      "source": [
        "encoded_imgs = encoder.predict(x_test)\r\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J-A52Q851br"
      },
      "source": [
        "### 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "dU4X2jB55RAV",
        "outputId": "46df31b7-15dc-4748-d218-d6ffeff9bf8d"
      },
      "source": [
        "n = 10  # 몇 개의 숫자를 나타낼 것인지\r\n",
        "plt.figure(figsize=(20, 4))\r\n",
        "for i in range(n):\r\n",
        "    # 원본 데이터\r\n",
        "    ax = plt.subplot(2, n, i + 1)\r\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "\r\n",
        "    # 재구성된 데이터\r\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\r\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bu64pjU6GJ0"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}