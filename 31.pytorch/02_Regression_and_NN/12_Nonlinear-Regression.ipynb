{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "- Non-linear data\n",
    "- linear model\n",
    "- y = 2x + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "viz = Visdom() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 1000\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std=10)\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -10, 6)\n",
    "y = -x**3 - 8*(x**2) + 3\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.cat([x, y_noise], 1)\n",
    "input_data.size() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize data with visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = viz.scatter(\n",
    "    X = input_data, \n",
    "    opts=dict(\n",
    "        xtickmin=-10,\n",
    "        xtickmax=6,\n",
    "        xtickstep=1,\n",
    "        ytickmin=-600,\n",
    "        ytickmax=300,\n",
    "        ytickstep=1,\n",
    "        markersymbol='dot',\n",
    "        markersize=5,\n",
    "        markercolor=np.random.randint(0, 255, num_data)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data = torch.cat([x, y], 1)\n",
    "win = viz.scatter(X = origin_data, win=win, update='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1)\n",
    "output = model(Variable(x))\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch No 0 tensor(20359.4688, grad_fn=<MseLossBackward>)\n",
      "epoch No 10 tensor(13857.6006, grad_fn=<MseLossBackward>)\n",
      "epoch No 20 tensor(12064.9473, grad_fn=<MseLossBackward>)\n",
      "epoch No 30 tensor(10808.5889, grad_fn=<MseLossBackward>)\n",
      "epoch No 40 tensor(9928.0850, grad_fn=<MseLossBackward>)\n",
      "epoch No 50 tensor(9310.9922, grad_fn=<MseLossBackward>)\n",
      "epoch No 60 tensor(8878.5088, grad_fn=<MseLossBackward>)\n",
      "epoch No 70 tensor(8575.4072, grad_fn=<MseLossBackward>)\n",
      "epoch No 80 tensor(8362.9824, grad_fn=<MseLossBackward>)\n",
      "epoch No 90 tensor(8214.1055, grad_fn=<MseLossBackward>)\n",
      "epoch No 100 tensor(8109.7686, grad_fn=<MseLossBackward>)\n",
      "epoch No 110 tensor(8036.6440, grad_fn=<MseLossBackward>)\n",
      "epoch No 120 tensor(7985.3970, grad_fn=<MseLossBackward>)\n",
      "epoch No 130 tensor(7949.4800, grad_fn=<MseLossBackward>)\n",
      "epoch No 140 tensor(7924.3071, grad_fn=<MseLossBackward>)\n",
      "epoch No 150 tensor(7906.6655, grad_fn=<MseLossBackward>)\n",
      "epoch No 160 tensor(7894.3018, grad_fn=<MseLossBackward>)\n",
      "epoch No 170 tensor(7885.6372, grad_fn=<MseLossBackward>)\n",
      "epoch No 180 tensor(7879.5640, grad_fn=<MseLossBackward>)\n",
      "epoch No 190 tensor(7875.3086, grad_fn=<MseLossBackward>)\n",
      "epoch No 200 tensor(7872.3247, grad_fn=<MseLossBackward>)\n",
      "epoch No 210 tensor(7870.2344, grad_fn=<MseLossBackward>)\n",
      "epoch No 220 tensor(7868.7690, grad_fn=<MseLossBackward>)\n",
      "epoch No 230 tensor(7867.7432, grad_fn=<MseLossBackward>)\n",
      "epoch No 240 tensor(7867.0229, grad_fn=<MseLossBackward>)\n",
      "epoch No 250 tensor(7866.5181, grad_fn=<MseLossBackward>)\n",
      "epoch No 260 tensor(7866.1655, grad_fn=<MseLossBackward>)\n",
      "epoch No 270 tensor(7865.9180, grad_fn=<MseLossBackward>)\n",
      "epoch No 280 tensor(7865.7446, grad_fn=<MseLossBackward>)\n",
      "epoch No 290 tensor(7865.6226, grad_fn=<MseLossBackward>)\n",
      "epoch No 300 tensor(7865.5376, grad_fn=<MseLossBackward>)\n",
      "epoch No 310 tensor(7865.4775, grad_fn=<MseLossBackward>)\n",
      "epoch No 320 tensor(7865.4355, grad_fn=<MseLossBackward>)\n",
      "epoch No 330 tensor(7865.4058, grad_fn=<MseLossBackward>)\n",
      "epoch No 340 tensor(7865.3848, grad_fn=<MseLossBackward>)\n",
      "epoch No 350 tensor(7865.3711, grad_fn=<MseLossBackward>)\n",
      "epoch No 360 tensor(7865.3604, grad_fn=<MseLossBackward>)\n",
      "epoch No 370 tensor(7865.3535, grad_fn=<MseLossBackward>)\n",
      "epoch No 380 tensor(7865.3477, grad_fn=<MseLossBackward>)\n",
      "epoch No 390 tensor(7865.3457, grad_fn=<MseLossBackward>)\n",
      "epoch No 400 tensor(7865.3423, grad_fn=<MseLossBackward>)\n",
      "epoch No 410 tensor(7865.3413, grad_fn=<MseLossBackward>)\n",
      "epoch No 420 tensor(7865.3408, grad_fn=<MseLossBackward>)\n",
      "epoch No 430 tensor(7865.3389, grad_fn=<MseLossBackward>)\n",
      "epoch No 440 tensor(7865.3389, grad_fn=<MseLossBackward>)\n",
      "epoch No 450 tensor(7865.3389, grad_fn=<MseLossBackward>)\n",
      "epoch No 460 tensor(7865.3379, grad_fn=<MseLossBackward>)\n",
      "epoch No 470 tensor(7865.3369, grad_fn=<MseLossBackward>)\n",
      "epoch No 480 tensor(7865.3384, grad_fn=<MseLossBackward>)\n",
      "epoch No 490 tensor(7865.3379, grad_fn=<MseLossBackward>)\n",
      "epoch No 500 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 510 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 520 tensor(7865.3364, grad_fn=<MseLossBackward>)\n",
      "epoch No 530 tensor(7865.3369, grad_fn=<MseLossBackward>)\n",
      "epoch No 540 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 550 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 560 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 570 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 580 tensor(7865.3369, grad_fn=<MseLossBackward>)\n",
      "epoch No 590 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 600 tensor(7865.3369, grad_fn=<MseLossBackward>)\n",
      "epoch No 610 tensor(7865.3379, grad_fn=<MseLossBackward>)\n",
      "epoch No 620 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 630 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 640 tensor(7865.3384, grad_fn=<MseLossBackward>)\n",
      "epoch No 650 tensor(7865.3369, grad_fn=<MseLossBackward>)\n",
      "epoch No 660 tensor(7865.3369, grad_fn=<MseLossBackward>)\n",
      "epoch No 670 tensor(7865.3384, grad_fn=<MseLossBackward>)\n",
      "epoch No 680 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 690 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 700 tensor(7865.3379, grad_fn=<MseLossBackward>)\n",
      "epoch No 710 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 720 tensor(7865.3379, grad_fn=<MseLossBackward>)\n",
      "epoch No 730 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 740 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 750 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 760 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 770 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 780 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 790 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 800 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 810 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 820 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 830 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 840 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 850 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 860 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 870 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 880 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 890 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 900 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 910 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 920 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 930 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 940 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 950 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 960 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 970 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 980 tensor(7865.3374, grad_fn=<MseLossBackward>)\n",
      "epoch No 990 tensor(7865.3374, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "label = Variable(y_noise)\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(Variable(x))\n",
    "    \n",
    "    loss = loss_func(output, label) \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print('epoch No', i, loss)\n",
    "        \n",
    "    loss_arr.append(loss.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-18.7751]]) tensor([-98.1028])\n"
     ]
    }
   ],
   "source": [
    "param_list = list(model.parameters())\n",
    "print(param_list[0].data, param_list[1].data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_2 = viz.scatter(\n",
    "    X = input_data,\n",
    "    opts=dict(\n",
    "        xtickmin=-10,\n",
    "        xtickmax=6,\n",
    "        xtickstep=1,\n",
    "        ytickmin=-600,\n",
    "        ytickmax=300,\n",
    "        ytickstep=1,\n",
    "        markersymbol='dot',\n",
    "        markercolor=np.random.randint(0, 255, num_data),\n",
    "        markersize=5,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = torch.cat([x, output.data], 1)\n",
    "win = viz.scatter(X = output_data, win=win_2, update='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Visualize loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape([i for i in range(num_epoch)], newshape=[num_epoch])\n",
    "loss_data = np.reshape(loss_arr, newshape=[num_epoch])\n",
    "\n",
    "win_3 = viz.line(X = x, Y = loss_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('vsc': conda)",
   "language": "python",
   "name": "python37764bitvscconda48cd1de58dbf4dbc9fea30418971662f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
