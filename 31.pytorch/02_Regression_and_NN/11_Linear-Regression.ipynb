{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "- linear data\n",
    "- linear model\n",
    "- y = 2x + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "viz = Visdom() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 1000\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std=1)\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -10, 10)\n",
    "y = 2*x + 3\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.cat([x, y_noise], 1)\n",
    "input_data.size() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize data with visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = viz.scatter(\n",
    "    X = input_data, \n",
    "    opts=dict(\n",
    "        xtickmin=-10,\n",
    "        xtickmax=10,\n",
    "        xtickstep=1,\n",
    "        ytickmin=-20,\n",
    "        ytickmax=20,\n",
    "        ytickstep=1,\n",
    "        markersymbol='dot',\n",
    "        markersize=5,\n",
    "        markercolor=np.random.randint(0, 255, num_data)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data = torch.cat([x, y], 1)\n",
    "win = viz.scatter(X = origin_data, win=win, update='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1)\n",
    "output = model(Variable(x))\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch No 0 tensor(160.3875, grad_fn=<MseLossBackward>)\n",
      "epoch No 10 tensor(11.2044, grad_fn=<MseLossBackward>)\n",
      "epoch No 20 tensor(7.7778, grad_fn=<MseLossBackward>)\n",
      "epoch No 30 tensor(5.4901, grad_fn=<MseLossBackward>)\n",
      "epoch No 40 tensor(3.9629, grad_fn=<MseLossBackward>)\n",
      "epoch No 50 tensor(2.9432, grad_fn=<MseLossBackward>)\n",
      "epoch No 60 tensor(2.2625, grad_fn=<MseLossBackward>)\n",
      "epoch No 70 tensor(1.8081, grad_fn=<MseLossBackward>)\n",
      "epoch No 80 tensor(1.5047, grad_fn=<MseLossBackward>)\n",
      "epoch No 90 tensor(1.3021, grad_fn=<MseLossBackward>)\n",
      "epoch No 100 tensor(1.1669, grad_fn=<MseLossBackward>)\n",
      "epoch No 110 tensor(1.0766, grad_fn=<MseLossBackward>)\n",
      "epoch No 120 tensor(1.0163, grad_fn=<MseLossBackward>)\n",
      "epoch No 130 tensor(0.9761, grad_fn=<MseLossBackward>)\n",
      "epoch No 140 tensor(0.9492, grad_fn=<MseLossBackward>)\n",
      "epoch No 150 tensor(0.9313, grad_fn=<MseLossBackward>)\n",
      "epoch No 160 tensor(0.9193, grad_fn=<MseLossBackward>)\n",
      "epoch No 170 tensor(0.9113, grad_fn=<MseLossBackward>)\n",
      "epoch No 180 tensor(0.9060, grad_fn=<MseLossBackward>)\n",
      "epoch No 190 tensor(0.9024, grad_fn=<MseLossBackward>)\n",
      "epoch No 200 tensor(0.9000, grad_fn=<MseLossBackward>)\n",
      "epoch No 210 tensor(0.8984, grad_fn=<MseLossBackward>)\n",
      "epoch No 220 tensor(0.8974, grad_fn=<MseLossBackward>)\n",
      "epoch No 230 tensor(0.8967, grad_fn=<MseLossBackward>)\n",
      "epoch No 240 tensor(0.8962, grad_fn=<MseLossBackward>)\n",
      "epoch No 250 tensor(0.8959, grad_fn=<MseLossBackward>)\n",
      "epoch No 260 tensor(0.8957, grad_fn=<MseLossBackward>)\n",
      "epoch No 270 tensor(0.8955, grad_fn=<MseLossBackward>)\n",
      "epoch No 280 tensor(0.8954, grad_fn=<MseLossBackward>)\n",
      "epoch No 290 tensor(0.8954, grad_fn=<MseLossBackward>)\n",
      "epoch No 300 tensor(0.8953, grad_fn=<MseLossBackward>)\n",
      "epoch No 310 tensor(0.8953, grad_fn=<MseLossBackward>)\n",
      "epoch No 320 tensor(0.8953, grad_fn=<MseLossBackward>)\n",
      "epoch No 330 tensor(0.8953, grad_fn=<MseLossBackward>)\n",
      "epoch No 340 tensor(0.8953, grad_fn=<MseLossBackward>)\n",
      "epoch No 350 tensor(0.8953, grad_fn=<MseLossBackward>)\n",
      "epoch No 360 tensor(0.8953, grad_fn=<MseLossBackward>)\n",
      "epoch No 370 tensor(0.8953, grad_fn=<MseLossBackward>)\n",
      "epoch No 380 tensor(0.8953, grad_fn=<MseLossBackward>)\n",
      "epoch No 390 tensor(0.8953, grad_fn=<MseLossBackward>)\n",
      "epoch No 400 tensor(0.8953, grad_fn=<MseLossBackward>)\n",
      "epoch No 410 tensor(0.8953, grad_fn=<MseLossBackward>)\n",
      "epoch No 420 tensor(0.8953, grad_fn=<MseLossBackward>)\n",
      "epoch No 430 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 440 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 450 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 460 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 470 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 480 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 490 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 500 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 510 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 520 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 530 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 540 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 550 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 560 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 570 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 580 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 590 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 600 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 610 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 620 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 630 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 640 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 650 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 660 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 670 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 680 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 690 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 700 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 710 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 720 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 730 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 740 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 750 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 760 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 770 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 780 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 790 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 800 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 810 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 820 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 830 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 840 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 850 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 860 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 870 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 880 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 890 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 900 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 910 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 920 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 930 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 940 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 950 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 960 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 970 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 980 tensor(0.8952, grad_fn=<MseLossBackward>)\n",
      "epoch No 990 tensor(0.8952, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "label = Variable(y_noise)\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(Variable(x))\n",
    "    \n",
    "    loss = loss_func(output, label) \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print('epoch No', i, loss)\n",
    "        \n",
    "    loss_arr.append(loss.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0053]]) tensor([2.9687])\n"
     ]
    }
   ],
   "source": [
    "param_list = list(model.parameters())\n",
    "print(param_list[0].data, param_list[1].data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_2 = viz.scatter(\n",
    "    X = input_data,\n",
    "    opts=dict(\n",
    "        xtickmin=-10,\n",
    "        xtickmax=10,\n",
    "        xtickstep=1,\n",
    "        ytickmin=-20,\n",
    "        ytickmax=20,\n",
    "        ytickstep=1,\n",
    "        markersymbol='dot',\n",
    "        markercolor=np.random.randint(0, 255, num_data),\n",
    "        markersize=5,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = torch.cat([x, output.data], 1)\n",
    "win = viz.scatter(X = output_data, win=win_2, update='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Visualize loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape([i for i in range(num_epoch)], newshape=[num_epoch])\n",
    "loss_data = np.reshape(loss_arr, newshape=[num_epoch])\n",
    "\n",
    "win_3 = viz.line(X = x, Y = loss_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('vsc': conda)",
   "language": "python",
   "name": "python37764bitvscconda48cd1de58dbf4dbc9fea30418971662f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
