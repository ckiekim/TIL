{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with Quadratic Data\n",
    "- y = x^2 + 3\n",
    "- 4 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from visdom import Visdom\n",
    "viz = Visdom() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 5000\n",
    "\n",
    "noise = init.normal_(torch.FloatTensor(num_data,1), std=3)\n",
    "x = init.uniform_(torch.Tensor(num_data,1), -15, 15)\n",
    "y = x**2 + 3\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.cat([x,y_noise],1) \n",
    "win = viz.scatter(\n",
    "    X = input_data,\n",
    "    opts=dict(\n",
    "        xtickmin=-15,\n",
    "        xtickmax=15,\n",
    "        xtickstep=1,\n",
    "        ytickmin=0,\n",
    "        ytickmax=230,\n",
    "        ytickstep=10,\n",
    "        markersymbol='dot',\n",
    "        markercolor=np.random.randint(0, 255, num_data),\n",
    "        markersize=3,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data = torch.cat([x, y], 1)\n",
    "win = viz.scatter(X = origin_data, win=win, update='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN with 4 hidden layers\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(1,6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10,6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6,1)\n",
    "        ).cuda()\n",
    "loss_func = nn.L1Loss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0005) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch No 0 tensor(78.6847, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 100 tensor(78.4766, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 200 tensor(78.2514, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 300 tensor(77.9680, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 400 tensor(77.5523, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 500 tensor(76.8322, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 600 tensor(75.2945, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 700 tensor(70.7346, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 800 tensor(43.3843, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 900 tensor(19.3564, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 1000 tensor(19.0211, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 1100 tensor(18.6786, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 1200 tensor(18.3201, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 1300 tensor(17.9386, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 1400 tensor(17.5387, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 1500 tensor(17.1225, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 1600 tensor(16.6836, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 1700 tensor(16.2198, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 1800 tensor(15.7018, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 1900 tensor(15.1368, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 2000 tensor(14.5133, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 2100 tensor(13.8378, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 2200 tensor(13.1230, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 2300 tensor(12.3589, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 2400 tensor(11.5632, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 2500 tensor(10.8145, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 2600 tensor(10.1121, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 2700 tensor(9.5198, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 2800 tensor(8.9722, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 2900 tensor(8.4997, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 3000 tensor(8.1401, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 3100 tensor(7.8480, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 3200 tensor(7.5912, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 3300 tensor(7.3753, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 3400 tensor(7.1989, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 3500 tensor(7.0351, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 3600 tensor(6.8844, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 3700 tensor(6.7540, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 3800 tensor(6.6157, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 3900 tensor(6.4519, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 4000 tensor(6.2461, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 4100 tensor(5.9977, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 4200 tensor(5.8267, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 4300 tensor(5.6381, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 4400 tensor(5.8528, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 4500 tensor(5.9351, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 4600 tensor(5.8647, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 4700 tensor(5.8416, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 4800 tensor(5.7335, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "epoch No 4900 tensor(5.7713, device='cuda:0', grad_fn=<L1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "label = Variable(y_noise.cuda())\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(Variable(x.cuda()))\n",
    "    \n",
    "    loss = loss_func(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print('epoch No', i, loss)\n",
    "    loss_arr.append(loss.cpu().data.numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.1816],\n",
      "        [ 0.6914],\n",
      "        [ 0.0862],\n",
      "        [-0.8359],\n",
      "        [-0.1469],\n",
      "        [-0.2567]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-1.5279, -2.1387, -0.7578, -0.7833, -1.4511, -1.8160], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.3170,  0.5966, -0.1891,  0.3047,  0.2720, -0.3270],\n",
      "        [ 0.6646,  1.3024,  0.0720,  0.3693,  0.8643,  0.6753],\n",
      "        [ 0.8588,  1.1702,  0.2778,  0.7369,  0.6208,  0.4772],\n",
      "        [-0.1771,  0.0081, -0.2661,  0.0847,  0.0703, -0.2567],\n",
      "        [ 0.0742,  0.4681,  0.0921, -0.1542,  0.0085, -0.2248],\n",
      "        [-0.0189, -0.1562, -0.3858,  0.2143,  0.2526, -0.2745],\n",
      "        [ 0.2466, -0.0247, -0.0374, -0.4023, -0.3548, -0.2375],\n",
      "        [ 0.3135,  0.6441, -0.1065,  0.0588,  0.1293,  0.5769],\n",
      "        [-0.2991, -0.3974, -0.2622, -0.1994, -0.1443, -0.3838],\n",
      "        [ 0.4492,  0.7102,  0.6890,  0.6102,  0.6239,  1.0386]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1130,  0.0340, -0.1827,  0.1523, -0.5926,  0.2512, -0.3772, -0.9702,\n",
      "        -0.3503, -1.8095], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2228,  0.1945, -0.1715, -0.2258, -0.1841, -0.0837, -0.0481, -0.1197,\n",
      "          0.2071, -0.0457],\n",
      "        [ 0.2364,  0.6860,  0.8751, -0.1215,  0.2309,  0.0310,  0.2776,  0.4991,\n",
      "          0.1274,  1.0848],\n",
      "        [-0.0238, -0.2884, -0.0037, -0.2075,  0.1553,  0.0822, -0.0827, -0.0359,\n",
      "          0.1861, -0.1122],\n",
      "        [ 0.1402,  0.1267, -0.1528, -0.0054,  0.1650,  0.0427, -0.1311, -0.1731,\n",
      "         -0.1645, -0.1903],\n",
      "        [-0.1546,  0.0829,  0.1975,  0.1632, -0.0716,  0.0949, -0.1847, -0.0227,\n",
      "         -0.0391, -0.2791],\n",
      "        [ 0.4531,  1.6069,  1.4865, -0.0617,  0.6019,  0.0420,  0.2759,  1.0661,\n",
      "          0.0707,  2.1440]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0661,  0.4267, -0.2438, -0.1437, -0.2103, -0.3001], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2380,  1.6641, -0.2700, -0.2831, -0.2451,  3.3226]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.0110], device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "param_list = list(model.parameters())\n",
    "print(param_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Trained Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "win2 = viz.scatter(\n",
    "    X = input_data,\n",
    "    opts=dict(\n",
    "        xtickmin=-15,\n",
    "        xtickmax=15,\n",
    "        xtickstep=1,\n",
    "        ytickmin=0,\n",
    "        ytickmax=230,\n",
    "        ytickstep=10,\n",
    "        markersymbol='dot',\n",
    "        markercolor=np.random.randint(0, 255, num_data),\n",
    "        markersize=3,\n",
    "    ),\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = torch.cat([x, output.cpu().data], 1)\n",
    "win = viz.scatter(X = output_data, win=win2, update='append') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape([i for i in range(num_epoch)], newshape=[num_epoch])\n",
    "loss_data = np.reshape(loss_arr, newshape=[num_epoch])\n",
    "\n",
    "win3 = viz.line(X = x, Y = loss_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('vsc': conda)",
   "language": "python",
   "name": "python37764bitvscconda48cd1de58dbf4dbc9fea30418971662f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
