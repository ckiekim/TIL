{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression\n",
    "- 1, 2, 3은 한번만 실행\n",
    "- 4, 5, 6은 반복해서 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 89, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hypothesis 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = w1x1 + w2x2 + w3x3 + b\n",
    "W = torch.zeros((3, 1), requires_grad=True)  # requires_grad=True 학습할 것이라 명시\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([W, b], lr=1e-5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 학습 (반복 실행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0/20 hypothesis: tensor([0., 0., 0., 0., 0.]), Cost: 29661.800781\n",
      "Epoch   1/20 hypothesis: tensor([67.3170, 81.1991, 79.7196, 86.8119, 61.7093]), Cost: 9274.123047\n",
      "Epoch   2/20 hypothesis: tensor([104.9560, 126.6004, 124.2935, 135.3513,  96.2133]), Cost: 2900.307617\n",
      "Epoch   3/20 hypothesis: tensor([126.0012, 151.9859, 149.2163, 162.4913, 115.5058]), Cost: 907.655945\n",
      "Epoch   4/20 hypothesis: tensor([137.7681, 166.1799, 163.1514, 177.6662, 126.2930]), Cost: 284.691467\n",
      "Epoch   5/20 hypothesis: tensor([144.3472, 174.1163, 170.9429, 186.1509, 132.3247]), Cost: 89.933189\n",
      "Epoch   6/20 hypothesis: tensor([148.0256, 178.5540, 175.2994, 190.8950, 135.6974]), Cost: 29.045380\n",
      "Epoch   7/20 hypothesis: tensor([150.0822, 181.0353, 177.7352, 193.5475, 137.5833]), Cost: 10.009595\n",
      "Epoch   8/20 hypothesis: tensor([151.2319, 182.4228, 179.0971, 195.0306, 138.6380]), Cost: 4.058017\n",
      "Epoch   9/20 hypothesis: tensor([151.8746, 183.1987, 179.8586, 195.8598, 139.2278]), Cost: 2.197037\n",
      "Epoch  10/20 hypothesis: tensor([152.2338, 183.6326, 180.2843, 196.3234, 139.5578]), Cost: 1.614841\n",
      "Epoch  11/20 hypothesis: tensor([152.4345, 183.8753, 180.5222, 196.5826, 139.7424]), Cost: 1.432478\n",
      "Epoch  12/20 hypothesis: tensor([152.5466, 184.0111, 180.6553, 196.7274, 139.8459]), Cost: 1.375102\n",
      "Epoch  13/20 hypothesis: tensor([152.6091, 184.0871, 180.7296, 196.8084, 139.9038]), Cost: 1.356806\n",
      "Epoch  14/20 hypothesis: tensor([152.6438, 184.1298, 180.7711, 196.8536, 139.9364]), Cost: 1.350702\n",
      "Epoch  15/20 hypothesis: tensor([152.6631, 184.1537, 180.7943, 196.8789, 139.9548]), Cost: 1.348451\n",
      "Epoch  16/20 hypothesis: tensor([152.6738, 184.1671, 180.8072, 196.8929, 139.9652]), Cost: 1.347371\n",
      "Epoch  17/20 hypothesis: tensor([152.6795, 184.1747, 180.8144, 196.9008, 139.9712]), Cost: 1.346669\n",
      "Epoch  18/20 hypothesis: tensor([152.6826, 184.1791, 180.8184, 196.9051, 139.9747]), Cost: 1.346087\n",
      "Epoch  19/20 hypothesis: tensor([152.6842, 184.1816, 180.8205, 196.9075, 139.9769]), Cost: 1.345549\n",
      "Epoch  20/20 hypothesis: tensor([152.6849, 184.1831, 180.8217, 196.9088, 139.9782]), Cost: 1.345018\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    # 4. hypothesis 예측\n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "    # 5. cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2) \n",
    "    \n",
    "    # 6. optimizer로 학습 (항상 붙어다니는 3줄)\n",
    "    optimizer.zero_grad()  # gradient 초기화\n",
    "    cost.backward()        # gradient 계산\n",
    "    optimizer.step()       # step()으로 개선\n",
    "    \n",
    "    print('Epoch {:3d}/{} hypothesis: {}, Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6678],\n",
       "         [0.6666],\n",
       "         [0.6746]], requires_grad=True),\n",
       " tensor([0.0078], requires_grad=True))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0/20 prediction: tensor([ 84.2724, 101.6793,  99.8285, 108.9838,  76.9923]), Cost: 5950.930664\n",
      "Epoch   1/20 prediction: tensor([114.4207, 138.0452, 135.5316, 147.8632, 104.6296]), Cost: 1861.618164\n",
      "Epoch   2/20 prediction: tensor([131.2774, 158.3788, 155.4944, 169.6020, 120.0827]), Cost: 583.173157\n",
      "Epoch   3/20 prediction: tensor([140.7025, 169.7480, 166.6562, 181.7568, 128.7233]), Cost: 183.491028\n",
      "Epoch   4/20 prediction: tensor([145.9721, 176.1051, 172.8971, 188.5529, 133.5547]), Cost: 58.537891\n",
      "Epoch   5/20 prediction: tensor([148.9184, 179.6596, 176.3866, 192.3528, 136.2562]), Cost: 19.473267\n",
      "Epoch   6/20 prediction: tensor([150.5656, 181.6471, 178.3376, 194.4774, 137.7670]), Cost: 7.259951\n",
      "Epoch   7/20 prediction: tensor([151.4864, 182.7586, 179.4284, 195.6653, 138.6118]), Cost: 3.441231\n",
      "Epoch   8/20 prediction: tensor([152.0011, 183.3801, 180.0383, 196.3295, 139.0844]), Cost: 2.246934\n",
      "Epoch   9/20 prediction: tensor([152.2887, 183.7277, 180.3793, 196.7008, 139.3488]), Cost: 1.873165\n",
      "Epoch  10/20 prediction: tensor([152.4494, 183.9222, 180.5699, 196.9084, 139.4968]), Cost: 1.755860\n",
      "Epoch  11/20 prediction: tensor([152.5390, 184.0310, 180.6764, 197.0244, 139.5797]), Cost: 1.718771\n",
      "Epoch  12/20 prediction: tensor([152.5890, 184.0920, 180.7359, 197.0892, 139.6263]), Cost: 1.706725\n",
      "Epoch  13/20 prediction: tensor([152.6167, 184.1262, 180.7691, 197.1254, 139.6525]), Cost: 1.702523\n",
      "Epoch  14/20 prediction: tensor([152.6321, 184.1454, 180.7876, 197.1456, 139.6673]), Cost: 1.700783\n",
      "Epoch  15/20 prediction: tensor([152.6405, 184.1562, 180.7980, 197.1568, 139.6758]), Cost: 1.699804\n",
      "Epoch  16/20 prediction: tensor([152.6450, 184.1624, 180.8037, 197.1631, 139.6807]), Cost: 1.699065\n",
      "Epoch  17/20 prediction: tensor([152.6474, 184.1660, 180.8068, 197.1665, 139.6836]), Cost: 1.698407\n",
      "Epoch  18/20 prediction: tensor([152.6486, 184.1681, 180.8086, 197.1684, 139.6855]), Cost: 1.697758\n",
      "Epoch  19/20 prediction: tensor([152.6490, 184.1693, 180.8095, 197.1694, 139.6866]), Cost: 1.697127\n",
      "Epoch  20/20 prediction: tensor([152.6491, 184.1701, 180.8099, 197.1699, 139.6875]), Cost: 1.696482\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    prediction = model(x_train)\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch {:3d}/{} prediction: {}, Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, prediction.squeeze().detach(), cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('vsc': conda)",
   "language": "python",
   "name": "python37764bitvscconda48cd1de58dbf4dbc9fea30418971662f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
