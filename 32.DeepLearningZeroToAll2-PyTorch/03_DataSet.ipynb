{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                       [93, 89, 93],\n",
    "                       [89, 91, 90],\n",
    "                       [96, 98, 100],\n",
    "                       [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y\n",
    "    \n",
    "dataset = CustomDataset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size = 2, shuffle = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0/20 Batch 1/3 Cost: 11110.126953\n",
      "Epoch   0/20 Batch 2/3 Cost: 4514.092285\n",
      "Epoch   0/20 Batch 3/3 Cost: 605.889465\n",
      "Epoch   1/20 Batch 1/3 Cost: 398.994812\n",
      "Epoch   1/20 Batch 2/3 Cost: 117.350174\n",
      "Epoch   1/20 Batch 3/3 Cost: 67.869278\n",
      "Epoch   2/20 Batch 1/3 Cost: 8.491963\n",
      "Epoch   2/20 Batch 2/3 Cost: 3.049115\n",
      "Epoch   2/20 Batch 3/3 Cost: 2.877345\n",
      "Epoch   3/20 Batch 1/3 Cost: 0.288756\n",
      "Epoch   3/20 Batch 2/3 Cost: 1.235967\n",
      "Epoch   3/20 Batch 3/3 Cost: 0.461125\n",
      "Epoch   4/20 Batch 1/3 Cost: 0.604591\n",
      "Epoch   4/20 Batch 2/3 Cost: 0.127355\n",
      "Epoch   4/20 Batch 3/3 Cost: 1.239973\n",
      "Epoch   5/20 Batch 1/3 Cost: 1.007104\n",
      "Epoch   5/20 Batch 2/3 Cost: 0.215375\n",
      "Epoch   5/20 Batch 3/3 Cost: 0.426967\n",
      "Epoch   6/20 Batch 1/3 Cost: 0.337843\n",
      "Epoch   6/20 Batch 2/3 Cost: 1.537375\n",
      "Epoch   6/20 Batch 3/3 Cost: 0.017887\n",
      "Epoch   7/20 Batch 1/3 Cost: 0.634651\n",
      "Epoch   7/20 Batch 2/3 Cost: 0.536812\n",
      "Epoch   7/20 Batch 3/3 Cost: 0.501772\n",
      "Epoch   8/20 Batch 1/3 Cost: 0.678529\n",
      "Epoch   8/20 Batch 2/3 Cost: 0.621584\n",
      "Epoch   8/20 Batch 3/3 Cost: 0.029941\n",
      "Epoch   9/20 Batch 1/3 Cost: 0.471423\n",
      "Epoch   9/20 Batch 2/3 Cost: 0.735955\n",
      "Epoch   9/20 Batch 3/3 Cost: 0.347808\n",
      "Epoch  10/20 Batch 1/3 Cost: 0.721506\n",
      "Epoch  10/20 Batch 2/3 Cost: 0.382582\n",
      "Epoch  10/20 Batch 3/3 Cost: 0.737241\n",
      "Epoch  11/20 Batch 1/3 Cost: 0.348408\n",
      "Epoch  11/20 Batch 2/3 Cost: 0.582402\n",
      "Epoch  11/20 Batch 3/3 Cost: 1.167756\n",
      "Epoch  12/20 Batch 1/3 Cost: 1.033762\n",
      "Epoch  12/20 Batch 2/3 Cost: 0.664187\n",
      "Epoch  12/20 Batch 3/3 Cost: 0.260733\n",
      "Epoch  13/20 Batch 1/3 Cost: 0.276553\n",
      "Epoch  13/20 Batch 2/3 Cost: 1.227742\n",
      "Epoch  13/20 Batch 3/3 Cost: 0.364913\n",
      "Epoch  14/20 Batch 1/3 Cost: 0.675640\n",
      "Epoch  14/20 Batch 2/3 Cost: 0.337528\n",
      "Epoch  14/20 Batch 3/3 Cost: 1.049174\n",
      "Epoch  15/20 Batch 1/3 Cost: 0.550092\n",
      "Epoch  15/20 Batch 2/3 Cost: 0.902462\n",
      "Epoch  15/20 Batch 3/3 Cost: 0.069595\n",
      "Epoch  16/20 Batch 1/3 Cost: 0.556901\n",
      "Epoch  16/20 Batch 2/3 Cost: 1.251175\n",
      "Epoch  16/20 Batch 3/3 Cost: 0.002075\n",
      "Epoch  17/20 Batch 1/3 Cost: 0.132319\n",
      "Epoch  17/20 Batch 2/3 Cost: 0.936936\n",
      "Epoch  17/20 Batch 3/3 Cost: 1.289945\n",
      "Epoch  18/20 Batch 1/3 Cost: 0.928075\n",
      "Epoch  18/20 Batch 2/3 Cost: 0.991604\n",
      "Epoch  18/20 Batch 3/3 Cost: 0.018509\n",
      "Epoch  19/20 Batch 1/3 Cost: 0.336112\n",
      "Epoch  19/20 Batch 2/3 Cost: 0.546380\n",
      "Epoch  19/20 Batch 3/3 Cost: 1.178730\n",
      "Epoch  20/20 Batch 1/3 Cost: 0.356230\n",
      "Epoch  20/20 Batch 2/3 Cost: 1.107666\n",
      "Epoch  20/20 Batch 3/3 Cost: 0.331693\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x_train, y_train = samples\n",
    "        prediction = model(x_train)\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch {:3d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, batch_idx+1, len(dataloader), cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('vsc': conda)",
   "language": "python",
   "name": "python37764bitvscconda48cd1de58dbf4dbc9fea30418971662f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
