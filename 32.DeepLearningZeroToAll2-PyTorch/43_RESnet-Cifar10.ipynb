{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESnet for Cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define value tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_tracker(value_plot, value, num):\n",
    "    '''num, loss_value, are Tensor'''\n",
    "    vis.line(X=num,\n",
    "             Y=value,\n",
    "             win = value_plot,\n",
    "             update='append'\n",
    "             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "#### How to Calculate mean and std in Normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "[125.30691805 122.95039414 113.86538318]\n",
      "[62.99321928 62.08870764 66.70489964]\n",
      "[0.49139968 0.48215841 0.44653091]\n",
      "[0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n",
    "print(trainset.data.shape)\n",
    "\n",
    "train_data_mean = trainset.data.mean( axis=(0,1,2) )\n",
    "train_data_std = trainset.data.std( axis=(0,1,2) )\n",
    "\n",
    "print(train_data_mean)\n",
    "print(train_data_std)\n",
    "\n",
    "train_data_mean = train_data_mean / 255\n",
    "train_data_std = train_data_std / 255\n",
    "\n",
    "print(train_data_mean)\n",
    "print(train_data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_data_mean, train_data_std)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_data_mean, train_data_std)\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,  # original 256\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,  # original 256\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models.resnet as resnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50 = resnet.resnet50().to(device)\n",
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(resnet50.parameters(), lr = 0.1, momentum = 0.9, weight_decay=5e-4)\n",
    "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))\n",
    "acc_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='Accuracy', legend=['Acc'], showlegend=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define acc_check function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_check(net, test_set, epoch, save=1):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_set:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    acc = (100 * correct / total)\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % acc)\n",
    "    if save:\n",
    "        torch.save(net.state_dict(), \"./model/model43_epoch_{}_acc_{}.pth\".format(epoch, int(acc)))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with acc_check and model_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    }
   ],
   "source": [
    "print(len(trainloader))\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ckkim\\.conda\\envs\\vsc\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  30] loss: 27.409385\n",
      "[1,  60] loss: 5.835786\n",
      "[1,  90] loss: 3.085668\n",
      "[1, 120] loss: 3.009681\n",
      "[1, 150] loss: 2.593116\n",
      "[1, 180] loss: 2.445443\n",
      "[1, 210] loss: 2.385295\n",
      "[1, 240] loss: 2.318121\n",
      "[1, 270] loss: 2.233349\n",
      "[1, 300] loss: 2.223538\n",
      "[1, 330] loss: 2.178525\n",
      "[1, 360] loss: 2.136535\n",
      "[1, 390] loss: 2.129084\n",
      "Accuracy of the network on the 10000 test images: 21 %\n",
      "[2,  30] loss: 2.090878\n",
      "[2,  60] loss: 2.095297\n",
      "[2,  90] loss: 2.093529\n",
      "[2, 120] loss: 2.090547\n",
      "[2, 150] loss: 2.057116\n",
      "[2, 180] loss: 2.051410\n",
      "[2, 210] loss: 2.031616\n",
      "[2, 240] loss: 2.032419\n",
      "[2, 270] loss: 2.030541\n",
      "[2, 300] loss: 2.016779\n",
      "[2, 330] loss: 1.983643\n",
      "[2, 360] loss: 1.970147\n",
      "[2, 390] loss: 1.960616\n",
      "Accuracy of the network on the 10000 test images: 28 %\n",
      "[3,  30] loss: 1.920305\n",
      "[3,  60] loss: 1.911338\n",
      "[3,  90] loss: 1.907330\n",
      "[3, 120] loss: 1.924827\n",
      "[3, 150] loss: 1.874581\n",
      "[3, 180] loss: 1.885273\n",
      "[3, 210] loss: 1.891991\n",
      "[3, 240] loss: 1.829887\n",
      "[3, 270] loss: 1.837494\n",
      "[3, 300] loss: 1.815921\n",
      "[3, 330] loss: 1.848081\n",
      "[3, 360] loss: 1.838174\n",
      "[3, 390] loss: 1.803721\n",
      "Accuracy of the network on the 10000 test images: 32 %\n",
      "[4,  30] loss: 1.802534\n",
      "[4,  60] loss: 1.804146\n",
      "[4,  90] loss: 1.779432\n",
      "[4, 120] loss: 1.779491\n",
      "[4, 150] loss: 1.771668\n",
      "[4, 180] loss: 1.784835\n",
      "[4, 210] loss: 1.793331\n",
      "[4, 240] loss: 1.754483\n",
      "[4, 270] loss: 1.779710\n",
      "[4, 300] loss: 1.760585\n",
      "[4, 330] loss: 1.734786\n",
      "[4, 360] loss: 1.714592\n",
      "[4, 390] loss: 1.743776\n",
      "Accuracy of the network on the 10000 test images: 34 %\n",
      "[5,  30] loss: 1.683671\n",
      "[5,  60] loss: 1.722662\n",
      "[5,  90] loss: 1.720723\n",
      "[5, 120] loss: 1.725921\n",
      "[5, 150] loss: 1.716087\n",
      "[5, 180] loss: 1.692987\n",
      "[5, 210] loss: 1.703204\n",
      "[5, 240] loss: 1.680780\n",
      "[5, 270] loss: 1.649156\n",
      "[5, 300] loss: 1.654165\n",
      "[5, 330] loss: 1.635093\n",
      "[5, 360] loss: 1.638915\n",
      "[5, 390] loss: 1.653857\n",
      "Accuracy of the network on the 10000 test images: 40 %\n",
      "[6,  30] loss: 1.656767\n",
      "[6,  60] loss: 1.647925\n",
      "[6,  90] loss: 1.629392\n",
      "[6, 120] loss: 1.585605\n",
      "[6, 150] loss: 1.603615\n",
      "[6, 180] loss: 1.561073\n",
      "[6, 210] loss: 1.600177\n",
      "[6, 240] loss: 1.581895\n",
      "[6, 270] loss: 1.601964\n",
      "[6, 300] loss: 1.572859\n",
      "[6, 330] loss: 1.533738\n",
      "[6, 360] loss: 1.561467\n",
      "[6, 390] loss: 1.557783\n",
      "Accuracy of the network on the 10000 test images: 44 %\n",
      "[7,  30] loss: 1.518558\n",
      "[7,  60] loss: 1.560376\n",
      "[7,  90] loss: 1.543998\n",
      "[7, 120] loss: 1.535621\n",
      "[7, 150] loss: 1.512354\n",
      "[7, 180] loss: 1.518849\n",
      "[7, 210] loss: 1.551899\n",
      "[7, 240] loss: 1.538587\n",
      "[7, 270] loss: 1.528841\n",
      "[7, 300] loss: 1.549091\n",
      "[7, 330] loss: 1.517459\n",
      "[7, 360] loss: 1.533942\n",
      "[7, 390] loss: 1.533614\n",
      "Accuracy of the network on the 10000 test images: 48 %\n",
      "[8,  30] loss: 1.481321\n",
      "[8,  60] loss: 1.505066\n",
      "[8,  90] loss: 1.479538\n",
      "[8, 120] loss: 1.508852\n",
      "[8, 150] loss: 1.484870\n",
      "[8, 180] loss: 1.443236\n",
      "[8, 210] loss: 1.492378\n",
      "[8, 240] loss: 1.459791\n",
      "[8, 270] loss: 1.448514\n",
      "[8, 300] loss: 1.479345\n",
      "[8, 330] loss: 1.475879\n",
      "[8, 360] loss: 1.464577\n",
      "[8, 390] loss: 1.421406\n",
      "Accuracy of the network on the 10000 test images: 47 %\n",
      "[9,  30] loss: 1.467206\n",
      "[9,  60] loss: 1.453714\n",
      "[9,  90] loss: 1.437404\n",
      "[9, 120] loss: 1.497080\n",
      "[9, 150] loss: 1.439541\n",
      "[9, 180] loss: 1.441407\n",
      "[9, 210] loss: 1.468225\n",
      "[9, 240] loss: 1.406898\n",
      "[9, 270] loss: 1.447801\n",
      "[9, 300] loss: 1.402558\n",
      "[9, 330] loss: 1.409146\n",
      "[9, 360] loss: 1.425071\n",
      "[9, 390] loss: 1.387629\n",
      "Accuracy of the network on the 10000 test images: 50 %\n",
      "[10,  30] loss: 1.350258\n",
      "[10,  60] loss: 1.305350\n",
      "[10,  90] loss: 1.295188\n",
      "[10, 120] loss: 1.312918\n",
      "[10, 150] loss: 1.351905\n",
      "[10, 180] loss: 1.313651\n",
      "[10, 210] loss: 1.319771\n",
      "[10, 240] loss: 1.330509\n",
      "[10, 270] loss: 1.280888\n",
      "[10, 300] loss: 1.315173\n",
      "[10, 330] loss: 1.287844\n",
      "[10, 360] loss: 1.262145\n",
      "[10, 390] loss: 1.243803\n",
      "Accuracy of the network on the 10000 test images: 54 %\n",
      "[11,  30] loss: 1.270891\n",
      "[11,  60] loss: 1.212245\n",
      "[11,  90] loss: 1.236925\n",
      "[11, 120] loss: 1.239061\n",
      "[11, 150] loss: 1.255920\n",
      "[11, 180] loss: 1.235347\n",
      "[11, 210] loss: 1.289968\n",
      "[11, 240] loss: 1.233121\n",
      "[11, 270] loss: 1.193269\n",
      "[11, 300] loss: 1.307145\n",
      "[11, 330] loss: 1.246130\n",
      "[11, 360] loss: 1.248435\n",
      "[11, 390] loss: 1.274710\n",
      "Accuracy of the network on the 10000 test images: 55 %\n",
      "[12,  30] loss: 1.228399\n",
      "[12,  60] loss: 1.225685\n",
      "[12,  90] loss: 1.229372\n",
      "[12, 120] loss: 1.240069\n",
      "[12, 150] loss: 1.217634\n",
      "[12, 180] loss: 1.220190\n",
      "[12, 210] loss: 1.220112\n",
      "[12, 240] loss: 1.217600\n",
      "[12, 270] loss: 1.188690\n",
      "[12, 300] loss: 1.198026\n",
      "[12, 330] loss: 1.158179\n",
      "[12, 360] loss: 1.224850\n",
      "[12, 390] loss: 1.176121\n",
      "Accuracy of the network on the 10000 test images: 56 %\n",
      "[13,  30] loss: 1.159147\n",
      "[13,  60] loss: 1.173482\n",
      "[13,  90] loss: 1.187441\n",
      "[13, 120] loss: 1.129358\n",
      "[13, 150] loss: 1.186661\n",
      "[13, 180] loss: 1.217529\n",
      "[13, 210] loss: 1.166137\n",
      "[13, 240] loss: 1.182620\n",
      "[13, 270] loss: 1.183165\n",
      "[13, 300] loss: 1.190095\n",
      "[13, 330] loss: 1.162080\n",
      "[13, 360] loss: 1.170861\n",
      "[13, 390] loss: 1.196630\n",
      "Accuracy of the network on the 10000 test images: 59 %\n",
      "[14,  30] loss: 1.122754\n",
      "[14,  60] loss: 1.162740\n",
      "[14,  90] loss: 1.130152\n",
      "[14, 120] loss: 1.183969\n",
      "[14, 150] loss: 1.198270\n",
      "[14, 180] loss: 1.189994\n",
      "[14, 210] loss: 1.188077\n",
      "[14, 240] loss: 1.186496\n",
      "[14, 270] loss: 1.185147\n",
      "[14, 300] loss: 1.147135\n",
      "[14, 330] loss: 1.106428\n",
      "[14, 360] loss: 1.136427\n",
      "[14, 390] loss: 1.154062\n",
      "Accuracy of the network on the 10000 test images: 57 %\n",
      "[15,  30] loss: 1.139153\n",
      "[15,  60] loss: 1.123826\n",
      "[15,  90] loss: 1.091484\n",
      "[15, 120] loss: 1.133133\n",
      "[15, 150] loss: 1.155271\n",
      "[15, 180] loss: 1.096168\n",
      "[15, 210] loss: 1.116566\n",
      "[15, 240] loss: 1.102189\n",
      "[15, 270] loss: 1.101188\n",
      "[15, 300] loss: 1.089271\n",
      "[15, 330] loss: 1.106675\n",
      "[15, 360] loss: 1.068446\n",
      "[15, 390] loss: 1.122561\n",
      "Accuracy of the network on the 10000 test images: 61 %\n",
      "[16,  30] loss: 1.054401\n",
      "[16,  60] loss: 1.078758\n",
      "[16,  90] loss: 1.053888\n",
      "[16, 120] loss: 1.088041\n",
      "[16, 150] loss: 1.073992\n",
      "[16, 180] loss: 1.072490\n",
      "[16, 210] loss: 1.105410\n",
      "[16, 240] loss: 1.111087\n",
      "[16, 270] loss: 1.029742\n",
      "[16, 300] loss: 1.027701\n",
      "[16, 330] loss: 1.059785\n",
      "[16, 360] loss: 1.015930\n",
      "[16, 390] loss: 1.041881\n",
      "Accuracy of the network on the 10000 test images: 62 %\n",
      "[17,  30] loss: 0.980460\n",
      "[17,  60] loss: 0.979968\n",
      "[17,  90] loss: 1.024141\n",
      "[17, 120] loss: 1.003376\n",
      "[17, 150] loss: 1.000277\n",
      "[17, 180] loss: 1.023579\n",
      "[17, 210] loss: 0.987710\n",
      "[17, 240] loss: 0.989306\n",
      "[17, 270] loss: 0.996106\n",
      "[17, 300] loss: 0.990687\n",
      "[17, 330] loss: 1.009684\n",
      "[17, 360] loss: 0.956217\n",
      "[17, 390] loss: 0.999122\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[18,  30] loss: 0.934531\n",
      "[18,  60] loss: 1.013799\n",
      "[18,  90] loss: 0.985106\n",
      "[18, 120] loss: 0.946578\n",
      "[18, 150] loss: 0.961775\n",
      "[18, 180] loss: 0.969385\n",
      "[18, 210] loss: 0.953588\n",
      "[18, 240] loss: 0.986756\n",
      "[18, 270] loss: 0.939154\n",
      "[18, 300] loss: 0.981727\n",
      "[18, 330] loss: 0.940201\n",
      "[18, 360] loss: 0.923743\n",
      "[18, 390] loss: 0.966761\n",
      "Accuracy of the network on the 10000 test images: 67 %\n",
      "[19,  30] loss: 0.898574\n",
      "[19,  60] loss: 0.943370\n",
      "[19,  90] loss: 0.891271\n",
      "[19, 120] loss: 0.932308\n",
      "[19, 150] loss: 0.947200\n",
      "[19, 180] loss: 0.918167\n",
      "[19, 210] loss: 0.939629\n",
      "[19, 240] loss: 0.915157\n",
      "[19, 270] loss: 0.903806\n",
      "[19, 300] loss: 0.910188\n",
      "[19, 330] loss: 0.864058\n",
      "[19, 360] loss: 0.941842\n",
      "[19, 390] loss: 0.939425\n",
      "Accuracy of the network on the 10000 test images: 67 %\n",
      "[20,  30] loss: 0.824312\n",
      "[20,  60] loss: 0.765691\n",
      "[20,  90] loss: 0.786459\n",
      "[20, 120] loss: 0.771109\n",
      "[20, 150] loss: 0.796605\n",
      "[20, 180] loss: 0.743112\n",
      "[20, 210] loss: 0.787629\n",
      "[20, 240] loss: 0.791218\n",
      "[20, 270] loss: 0.764969\n",
      "[20, 300] loss: 0.764762\n",
      "[20, 330] loss: 0.765492\n",
      "[20, 360] loss: 0.764137\n",
      "[20, 390] loss: 0.769811\n",
      "Accuracy of the network on the 10000 test images: 71 %\n",
      "[21,  30] loss: 0.748007\n",
      "[21,  60] loss: 0.736087\n",
      "[21,  90] loss: 0.719322\n",
      "[21, 120] loss: 0.714720\n",
      "[21, 150] loss: 0.733898\n",
      "[21, 180] loss: 0.732301\n",
      "[21, 210] loss: 0.708663\n",
      "[21, 240] loss: 0.723924\n",
      "[21, 270] loss: 0.752593\n",
      "[21, 300] loss: 0.776432\n",
      "[21, 330] loss: 0.755542\n",
      "[21, 360] loss: 0.768036\n",
      "[21, 390] loss: 0.726626\n",
      "Accuracy of the network on the 10000 test images: 71 %\n",
      "[22,  30] loss: 0.718589\n",
      "[22,  60] loss: 0.671690\n",
      "[22,  90] loss: 0.721605\n",
      "[22, 120] loss: 0.714788\n",
      "[22, 150] loss: 0.706419\n",
      "[22, 180] loss: 0.701575\n",
      "[22, 210] loss: 0.751733\n",
      "[22, 240] loss: 0.708764\n",
      "[22, 270] loss: 0.720877\n",
      "[22, 300] loss: 0.733184\n",
      "[22, 330] loss: 0.711770\n",
      "[22, 360] loss: 0.719336\n",
      "[22, 390] loss: 0.747572\n",
      "Accuracy of the network on the 10000 test images: 72 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23,  30] loss: 0.666250\n",
      "[23,  60] loss: 0.689345\n",
      "[23,  90] loss: 0.703966\n",
      "[23, 120] loss: 0.692183\n",
      "[23, 150] loss: 0.697008\n",
      "[23, 180] loss: 0.721590\n",
      "[23, 210] loss: 0.692079\n",
      "[23, 240] loss: 0.704106\n",
      "[23, 270] loss: 0.732356\n",
      "[23, 300] loss: 0.727052\n",
      "[23, 330] loss: 0.714798\n",
      "[23, 360] loss: 0.695719\n",
      "[23, 390] loss: 0.737959\n",
      "Accuracy of the network on the 10000 test images: 72 %\n",
      "[24,  30] loss: 0.689716\n",
      "[24,  60] loss: 0.667040\n",
      "[24,  90] loss: 0.712589\n",
      "[24, 120] loss: 0.689567\n",
      "[24, 150] loss: 0.670626\n",
      "[24, 180] loss: 0.671976\n",
      "[24, 210] loss: 0.695286\n",
      "[24, 240] loss: 0.687247\n",
      "[24, 270] loss: 0.686635\n",
      "[24, 300] loss: 0.669196\n",
      "[24, 330] loss: 0.699553\n",
      "[24, 360] loss: 0.723800\n",
      "[24, 390] loss: 0.692473\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "[25,  30] loss: 0.633114\n",
      "[25,  60] loss: 0.661258\n",
      "[25,  90] loss: 0.665628\n",
      "[25, 120] loss: 0.685356\n",
      "[25, 150] loss: 0.671417\n",
      "[25, 180] loss: 0.670403\n",
      "[25, 210] loss: 0.674737\n",
      "[25, 240] loss: 0.686046\n",
      "[25, 270] loss: 0.716559\n",
      "[25, 300] loss: 0.663835\n",
      "[25, 330] loss: 0.676631\n",
      "[25, 360] loss: 0.666413\n",
      "[25, 390] loss: 0.663530\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "[26,  30] loss: 0.621514\n",
      "[26,  60] loss: 0.629439\n",
      "[26,  90] loss: 0.644010\n",
      "[26, 120] loss: 0.684167\n",
      "[26, 150] loss: 0.660832\n",
      "[26, 180] loss: 0.667151\n",
      "[26, 210] loss: 0.667187\n",
      "[26, 240] loss: 0.667275\n",
      "[26, 270] loss: 0.673885\n",
      "[26, 300] loss: 0.635403\n",
      "[26, 330] loss: 0.693240\n",
      "[26, 360] loss: 0.638144\n",
      "[26, 390] loss: 0.653490\n",
      "Accuracy of the network on the 10000 test images: 74 %\n",
      "[27,  30] loss: 0.629696\n",
      "[27,  60] loss: 0.641219\n",
      "[27,  90] loss: 0.638375\n",
      "[27, 120] loss: 0.649318\n",
      "[27, 150] loss: 0.647015\n",
      "[27, 180] loss: 0.617811\n",
      "[27, 210] loss: 0.654968\n",
      "[27, 240] loss: 0.660121\n",
      "[27, 270] loss: 0.641419\n",
      "[27, 300] loss: 0.680581\n",
      "[27, 330] loss: 0.638115\n",
      "[27, 360] loss: 0.656659\n",
      "[27, 390] loss: 0.666452\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "[28,  30] loss: 0.593542\n",
      "[28,  60] loss: 0.616300\n",
      "[28,  90] loss: 0.634640\n",
      "[28, 120] loss: 0.667465\n",
      "[28, 150] loss: 0.655539\n",
      "[28, 180] loss: 0.680573\n",
      "[28, 210] loss: 0.635783\n",
      "[28, 240] loss: 0.651144\n",
      "[28, 270] loss: 0.625320\n",
      "[28, 300] loss: 0.662387\n",
      "[28, 330] loss: 0.648048\n",
      "[28, 360] loss: 0.646624\n",
      "[28, 390] loss: 0.623414\n",
      "Accuracy of the network on the 10000 test images: 74 %\n",
      "[29,  30] loss: 0.580928\n",
      "[29,  60] loss: 0.581866\n",
      "[29,  90] loss: 0.616779\n",
      "[29, 120] loss: 0.657938\n",
      "[29, 150] loss: 0.612495\n",
      "[29, 180] loss: 0.630375\n",
      "[29, 210] loss: 0.657759\n",
      "[29, 240] loss: 0.635030\n",
      "[29, 270] loss: 0.646673\n",
      "[29, 300] loss: 0.615274\n",
      "[29, 330] loss: 0.599065\n",
      "[29, 360] loss: 0.597897\n",
      "[29, 390] loss: 0.639232\n",
      "Accuracy of the network on the 10000 test images: 74 %\n",
      "[30,  30] loss: 0.559514\n",
      "[30,  60] loss: 0.533600\n",
      "[30,  90] loss: 0.506186\n",
      "[30, 120] loss: 0.505203\n",
      "[30, 150] loss: 0.497843\n",
      "[30, 180] loss: 0.498263\n",
      "[30, 210] loss: 0.518942\n",
      "[30, 240] loss: 0.523551\n",
      "[30, 270] loss: 0.496511\n",
      "[30, 300] loss: 0.541401\n",
      "[30, 330] loss: 0.526471\n",
      "[30, 360] loss: 0.497869\n",
      "[30, 390] loss: 0.508920\n",
      "Accuracy of the network on the 10000 test images: 76 %\n",
      "[31,  30] loss: 0.481002\n",
      "[31,  60] loss: 0.481085\n",
      "[31,  90] loss: 0.490162\n",
      "[31, 120] loss: 0.484186\n",
      "[31, 150] loss: 0.463692\n",
      "[31, 180] loss: 0.463378\n",
      "[31, 210] loss: 0.479614\n",
      "[31, 240] loss: 0.491414\n",
      "[31, 270] loss: 0.513325\n",
      "[31, 300] loss: 0.486259\n",
      "[31, 330] loss: 0.471124\n",
      "[31, 360] loss: 0.478038\n",
      "[31, 390] loss: 0.497787\n",
      "Accuracy of the network on the 10000 test images: 77 %\n",
      "[32,  30] loss: 0.451319\n",
      "[32,  60] loss: 0.452668\n",
      "[32,  90] loss: 0.450687\n",
      "[32, 120] loss: 0.478198\n",
      "[32, 150] loss: 0.486073\n",
      "[32, 180] loss: 0.482530\n",
      "[32, 210] loss: 0.457846\n",
      "[32, 240] loss: 0.467319\n",
      "[32, 270] loss: 0.478932\n",
      "[32, 300] loss: 0.461835\n",
      "[32, 330] loss: 0.486561\n",
      "[32, 360] loss: 0.484897\n",
      "[32, 390] loss: 0.503741\n",
      "Accuracy of the network on the 10000 test images: 77 %\n",
      "[33,  30] loss: 0.423885\n",
      "[33,  60] loss: 0.436158\n",
      "[33,  90] loss: 0.477280\n",
      "[33, 120] loss: 0.468251\n",
      "[33, 150] loss: 0.466809\n",
      "[33, 180] loss: 0.450321\n",
      "[33, 210] loss: 0.479814\n",
      "[33, 240] loss: 0.455187\n",
      "[33, 270] loss: 0.473317\n",
      "[33, 300] loss: 0.494272\n",
      "[33, 330] loss: 0.490734\n",
      "[33, 360] loss: 0.478372\n",
      "[33, 390] loss: 0.478664\n",
      "Accuracy of the network on the 10000 test images: 77 %\n",
      "[34,  30] loss: 0.432936\n",
      "[34,  60] loss: 0.445531\n",
      "[34,  90] loss: 0.456042\n",
      "[34, 120] loss: 0.450777\n",
      "[34, 150] loss: 0.449053\n",
      "[34, 180] loss: 0.444470\n",
      "[34, 210] loss: 0.462706\n",
      "[34, 240] loss: 0.478296\n",
      "[34, 270] loss: 0.457017\n",
      "[34, 300] loss: 0.479184\n",
      "[34, 330] loss: 0.452590\n",
      "[34, 360] loss: 0.453286\n",
      "[34, 390] loss: 0.440622\n",
      "Accuracy of the network on the 10000 test images: 77 %\n",
      "[35,  30] loss: 0.420752\n",
      "[35,  60] loss: 0.436628\n",
      "[35,  90] loss: 0.437647\n",
      "[35, 120] loss: 0.414096\n",
      "[35, 150] loss: 0.441646\n",
      "[35, 180] loss: 0.445914\n",
      "[35, 210] loss: 0.461150\n",
      "[35, 240] loss: 0.462857\n",
      "[35, 270] loss: 0.451809\n",
      "[35, 300] loss: 0.463653\n",
      "[35, 330] loss: 0.462170\n",
      "[35, 360] loss: 0.477709\n",
      "[35, 390] loss: 0.471923\n",
      "Accuracy of the network on the 10000 test images: 76 %\n",
      "[36,  30] loss: 0.435000\n",
      "[36,  60] loss: 0.440721\n",
      "[36,  90] loss: 0.437312\n",
      "[36, 120] loss: 0.448118\n",
      "[36, 150] loss: 0.443437\n",
      "[36, 180] loss: 0.417792\n",
      "[36, 210] loss: 0.442705\n",
      "[36, 240] loss: 0.489735\n",
      "[36, 270] loss: 0.446123\n",
      "[36, 300] loss: 0.471363\n",
      "[36, 330] loss: 0.447263\n",
      "[36, 360] loss: 0.466772\n",
      "[36, 390] loss: 0.447800\n",
      "Accuracy of the network on the 10000 test images: 77 %\n",
      "[37,  30] loss: 0.422114\n",
      "[37,  60] loss: 0.413400\n",
      "[37,  90] loss: 0.410648\n",
      "[37, 120] loss: 0.425809\n",
      "[37, 150] loss: 0.438743\n",
      "[37, 180] loss: 0.442624\n",
      "[37, 210] loss: 0.422077\n",
      "[37, 240] loss: 0.455866\n",
      "[37, 270] loss: 0.457747\n",
      "[37, 300] loss: 0.451157\n",
      "[37, 330] loss: 0.459174\n",
      "[37, 360] loss: 0.465180\n",
      "[37, 390] loss: 0.441163\n",
      "Accuracy of the network on the 10000 test images: 77 %\n",
      "[38,  30] loss: 0.401522\n",
      "[38,  60] loss: 0.407705\n",
      "[38,  90] loss: 0.410585\n",
      "[38, 120] loss: 0.415847\n",
      "[38, 150] loss: 0.417779\n",
      "[38, 180] loss: 0.458062\n",
      "[38, 210] loss: 0.434135\n",
      "[38, 240] loss: 0.447803\n",
      "[38, 270] loss: 0.428985\n",
      "[38, 300] loss: 0.417921\n",
      "[38, 330] loss: 0.458340\n",
      "[38, 360] loss: 0.456627\n",
      "[38, 390] loss: 0.447657\n",
      "Accuracy of the network on the 10000 test images: 77 %\n",
      "[39,  30] loss: 0.402733\n",
      "[39,  60] loss: 0.392260\n",
      "[39,  90] loss: 0.397538\n",
      "[39, 120] loss: 0.421622\n",
      "[39, 150] loss: 0.403499\n",
      "[39, 180] loss: 0.414589\n",
      "[39, 210] loss: 0.433222\n",
      "[39, 240] loss: 0.434560\n",
      "[39, 270] loss: 0.433875\n",
      "[39, 300] loss: 0.424532\n",
      "[39, 330] loss: 0.436725\n",
      "[39, 360] loss: 0.452403\n",
      "[39, 390] loss: 0.450792\n",
      "Accuracy of the network on the 10000 test images: 77 %\n",
      "[40,  30] loss: 0.383903\n",
      "[40,  60] loss: 0.327575\n",
      "[40,  90] loss: 0.332891\n",
      "[40, 120] loss: 0.325394\n",
      "[40, 150] loss: 0.332779\n",
      "[40, 180] loss: 0.338984\n",
      "[40, 210] loss: 0.327201\n",
      "[40, 240] loss: 0.337212\n",
      "[40, 270] loss: 0.321844\n",
      "[40, 300] loss: 0.324972\n",
      "[40, 330] loss: 0.335077\n",
      "[40, 360] loss: 0.331775\n",
      "[40, 390] loss: 0.330270\n",
      "Accuracy of the network on the 10000 test images: 78 %\n",
      "[41,  30] loss: 0.302821\n",
      "[41,  60] loss: 0.290141\n",
      "[41,  90] loss: 0.302416\n",
      "[41, 120] loss: 0.297333\n",
      "[41, 150] loss: 0.305780\n",
      "[41, 180] loss: 0.315848\n",
      "[41, 210] loss: 0.308096\n",
      "[41, 240] loss: 0.316846\n",
      "[41, 270] loss: 0.310164\n",
      "[41, 300] loss: 0.316723\n",
      "[41, 330] loss: 0.332125\n",
      "[41, 360] loss: 0.315387\n",
      "[41, 390] loss: 0.321299\n",
      "Accuracy of the network on the 10000 test images: 79 %\n",
      "[42,  30] loss: 0.264908\n",
      "[42,  60] loss: 0.285590\n",
      "[42,  90] loss: 0.312562\n",
      "[42, 120] loss: 0.283435\n",
      "[42, 150] loss: 0.282040\n",
      "[42, 180] loss: 0.302577\n",
      "[42, 210] loss: 0.314505\n",
      "[42, 240] loss: 0.293269\n",
      "[42, 270] loss: 0.298475\n",
      "[42, 300] loss: 0.319277\n",
      "[42, 330] loss: 0.301355\n",
      "[42, 360] loss: 0.328947\n",
      "[42, 390] loss: 0.306104\n",
      "Accuracy of the network on the 10000 test images: 78 %\n",
      "[43,  30] loss: 0.290856\n",
      "[43,  60] loss: 0.273528\n",
      "[43,  90] loss: 0.300739\n",
      "[43, 120] loss: 0.287371\n",
      "[43, 150] loss: 0.293310\n",
      "[43, 180] loss: 0.279735\n",
      "[43, 210] loss: 0.270496\n",
      "[43, 240] loss: 0.260766\n",
      "[43, 270] loss: 0.298894\n",
      "[43, 300] loss: 0.307760\n",
      "[43, 330] loss: 0.292042\n",
      "[43, 360] loss: 0.293528\n",
      "[43, 390] loss: 0.316949\n",
      "Accuracy of the network on the 10000 test images: 79 %\n",
      "[44,  30] loss: 0.260953\n",
      "[44,  60] loss: 0.259513\n",
      "[44,  90] loss: 0.257992\n",
      "[44, 120] loss: 0.280889\n",
      "[44, 150] loss: 0.263573\n",
      "[44, 180] loss: 0.282799\n",
      "[44, 210] loss: 0.292906\n",
      "[44, 240] loss: 0.296552\n",
      "[44, 270] loss: 0.282288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 300] loss: 0.274154\n",
      "[44, 330] loss: 0.315188\n",
      "[44, 360] loss: 0.295402\n",
      "[44, 390] loss: 0.314889\n",
      "Accuracy of the network on the 10000 test images: 78 %\n",
      "[45,  30] loss: 0.245391\n",
      "[45,  60] loss: 0.245535\n",
      "[45,  90] loss: 0.264300\n",
      "[45, 120] loss: 0.259023\n",
      "[45, 150] loss: 0.262467\n",
      "[45, 180] loss: 0.272797\n",
      "[45, 210] loss: 0.265561\n",
      "[45, 240] loss: 0.302858\n",
      "[45, 270] loss: 0.287992\n",
      "[45, 300] loss: 0.296672\n",
      "[45, 330] loss: 0.302868\n",
      "[45, 360] loss: 0.293943\n",
      "[45, 390] loss: 0.316982\n",
      "Accuracy of the network on the 10000 test images: 78 %\n",
      "[46,  30] loss: 0.263464\n",
      "[46,  60] loss: 0.247340\n",
      "[46,  90] loss: 0.248210\n",
      "[46, 120] loss: 0.259375\n",
      "[46, 150] loss: 0.254894\n",
      "[46, 180] loss: 0.280588\n",
      "[46, 210] loss: 0.273426\n",
      "[46, 240] loss: 0.301519\n",
      "[46, 270] loss: 0.278818\n",
      "[46, 300] loss: 0.293565\n",
      "[46, 330] loss: 0.270976\n",
      "[46, 360] loss: 0.302437\n",
      "[46, 390] loss: 0.286020\n",
      "Accuracy of the network on the 10000 test images: 78 %\n",
      "[47,  30] loss: 0.256410\n",
      "[47,  60] loss: 0.235320\n",
      "[47,  90] loss: 0.263498\n",
      "[47, 120] loss: 0.261288\n",
      "[47, 150] loss: 0.265133\n",
      "[47, 180] loss: 0.246430\n",
      "[47, 210] loss: 0.265692\n",
      "[47, 240] loss: 0.275641\n",
      "[47, 270] loss: 0.276655\n",
      "[47, 300] loss: 0.289659\n",
      "[47, 330] loss: 0.285716\n",
      "[47, 360] loss: 0.282679\n",
      "[47, 390] loss: 0.296534\n",
      "Accuracy of the network on the 10000 test images: 78 %\n",
      "[48,  30] loss: 0.268071\n",
      "[48,  60] loss: 0.253601\n",
      "[48,  90] loss: 0.269204\n",
      "[48, 120] loss: 0.257602\n",
      "[48, 150] loss: 0.261203\n",
      "[48, 180] loss: 0.271361\n",
      "[48, 210] loss: 0.267101\n",
      "[48, 240] loss: 0.283739\n",
      "[48, 270] loss: 0.291150\n",
      "[48, 300] loss: 0.275535\n",
      "[48, 330] loss: 0.281810\n",
      "[48, 360] loss: 0.262874\n",
      "[48, 390] loss: 0.300959\n",
      "Accuracy of the network on the 10000 test images: 79 %\n",
      "[49,  30] loss: 0.226379\n",
      "[49,  60] loss: 0.243101\n",
      "[49,  90] loss: 0.242420\n",
      "[49, 120] loss: 0.255511\n",
      "[49, 150] loss: 0.258418\n",
      "[49, 180] loss: 0.248867\n",
      "[49, 210] loss: 0.242051\n",
      "[49, 240] loss: 0.286255\n",
      "[49, 270] loss: 0.275772\n",
      "[49, 300] loss: 0.260219\n",
      "[49, 330] loss: 0.279523\n",
      "[49, 360] loss: 0.291390\n",
      "[49, 390] loss: 0.274497\n",
      "Accuracy of the network on the 10000 test images: 79 %\n",
      "[50,  30] loss: 0.213598\n",
      "[50,  60] loss: 0.213850\n",
      "[50,  90] loss: 0.204611\n",
      "[50, 120] loss: 0.190056\n",
      "[50, 150] loss: 0.209686\n",
      "[50, 180] loss: 0.209002\n",
      "[50, 210] loss: 0.201590\n",
      "[50, 240] loss: 0.193071\n",
      "[50, 270] loss: 0.194819\n",
      "[50, 300] loss: 0.211455\n",
      "[50, 330] loss: 0.195018\n",
      "[50, 360] loss: 0.201295\n",
      "[50, 390] loss: 0.205926\n",
      "Accuracy of the network on the 10000 test images: 79 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    lr_sche.step()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 30 == 29:    # print every 30 mini-batches\n",
    "            value_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch*len(trainloader) ]))\n",
    "            print('[%d, %3d] loss: %.6f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 30))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # Check Accuracy\n",
    "    acc = acc_check(resnet50, testloader, epoch, save=1)\n",
    "    value_tracker(acc_plt, torch.Tensor([acc]), torch.Tensor([epoch]))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![loss](images/43_ResNet_Cifar10-loss.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![accuracy](images/43_ResNet_Cifar10-accuracy.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 79.76 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = resnet50(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %5.2f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('vsc': conda)",
   "language": "python",
   "name": "python37764bitvscconda48cd1de58dbf4dbc9fea30418971662f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
