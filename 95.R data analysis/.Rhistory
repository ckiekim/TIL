install.packages("dplyr")
library(dplry)
library(dplyr)
df <- read.csv(file = "data/house_price_prediction.csv", header = TRUE,  sep = ",")
df <- df %>%
mutate(price_cat = factor(ifeles(price <= 50000, 'L', 'H')))
df <- df %>%
mutate(price_cat = factor(ifelse(price <= 50000, 'L', 'H')))
head(df)
dim(df)
set.seed(2024)
n <- nrow(df)
train_indices <- sample(seq_len(n), size = round(0.75 * n)) # 75%는 train
train <- df[train_indices, ]                                # train 데이터
test <- df[-train_indices, ]                                # test 데이터
print(nrow(train), nrow(test))
print(nrow(train), nrow(test))
dim(train)
dim(test)
# 4. C50 라이브러리의 분류 트리 모델 생성
install.packages("C50")
library(C50)
C50_model <- C5.0(price_cat ~ ., data = train)
# 모델 요약 출력
summary(c50_model)
summary(c50_model)
c50_model <- C5.0(price_cat ~ ., data = train)
summary(c50_model)
# 트리 시각화 (RStudio에서만 가능)
plot(c50_model)
df <- df %>%
mutate(price_cat = factor(ifelse(price <= 500000, 'L', 'H')))
head(df)
set.seed(2024)
n <- nrow(df)
train_indices <- sample(seq_len(n), size = round(0.75 * n)) # 75%는 train
train <- df[train_indices, ]                                # train 데이터
test <- df[-train_indices, ]                                # test 데이터
dim(train)
dim(test)
c50_model <- C5.0(price_cat ~ ., data = train)
# 모델 요약 출력
summary(c50_model)
# 트리 시각화 (RStudio에서만 가능)
plot(c50_model)
c50_model <- C5.0(price_cat ~ . -price, data = train)
# 모델 요약 출력
summary(c50_model)
# 트리 시각화 (RStudio에서만 가능)
plot(c50_model)
train_no_price <- train[, !names(train) %in% "price"]
c50_model <- C5.0(price_cat ~ ., data = train_no_price)
# 모델 요약 출력
summary(c50_model)
# 트리 시각화 (RStudio에서만 가능)
plot(c50_model)
# 5. 4.의 모델을 통한 예측 및 교차표 생성
test_no_price <- test[, !names(test) %in% "price"]
predictions <- predict(c50_model, newdata = test_no_price)
confusion_matrix <- table(test_no_price$price_cat, predictions)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
df <- df %>%
mutate(price_cat = factor(ifelse(price <= 500000, 'L', 'H'))) %>%
select(-price)
head(df)
set.seed(2024)
n <- nrow(df)
train_indices <- sample(seq_len(n), size = round(0.75 * n)) # 75%는 train
train <- df[train_indices, ]                                # train 데이터
test <- df[-train_indices, ]                                # test 데이터
dim(train)
dim(test)
# 분류 트리 모델 생성
c50_model <- C5.0(price_cat ~ ., data = train)
# 모델 요약 출력
summary(c50_model)
# 트리 시각화 (RStudio에서만 가능)
plot(c50_model)
# test 데이터에 대해 예측
predictions <- predict(c50_model, newdata = test)
confusion_matrix <- table(test$price_cat, predictions)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
boosted_model <- C5.0(price_cat ~ ., data = train, trials = 10)
predictions <- predict(boosted_model, newdata = test)
confusion_matrix <- table(test$Species, predictions)
confusion_matrix <- table(test$price_cat, predictions)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy with Boosting:", accuracy, "\n")
or (count in 1:10) {
for (count in 1:10) {
boosted_model <- C5.0(price_cat ~ ., data = train, trials = 10 * count)
predictions <- predict(boosted_model, newdata = test)
confusion_matrix <- table(test$price_cat, predictions)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Trials의 갯수:", 10 * count, "Accuracy with Boosting:", accuracy, "\n")
}
for (count in 1:5) {
boosted_model <- C5.0(price_cat ~ ., data = train, trials = 10 * count)
predictions <- predict(boosted_model, newdata = test)
confusion_matrix <- table(test$price_cat, predictions)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Trials의 갯수:", 10 * count, ", Accuracy with Boosting:", accuracy, "\n")
}
for (count in 1:8) {
boosted_model <- C5.0(price_cat ~ ., data = train, trials = 5 * count)
predictions <- predict(boosted_model, newdata = test)
confusion_matrix <- table(test$price_cat, predictions)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Trials의 갯수:", 10 * count, ", Accuracy with Boosting:", accuracy, "\n")
}
for (count in 1:8) {
boosted_model <- C5.0(price_cat ~ ., data = train, trials = 5 * count)
predictions <- predict(boosted_model, newdata = test)
confusion_matrix <- table(test$price_cat, predictions)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Trials의 갯수:", 5 * count, "--> Accuracy with Boosting:", accuracy, "\n")
}
# 데이터 구조 확인
str(df)
# 데이터프레임의 차원 확인
dim(df)
dim(train)
dim(test)
for (count in 1:11) {
boosted_model <- C5.0(price_cat ~ ., data = train, trials = 3 * count)
predictions <- predict(boosted_model, newdata = test)
confusion_matrix <- table(test$price_cat, predictions)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Trials의 갯수:", 3 * count, "--> Accuracy with Boosting:", accuracy, "\n")
}
confusion_matrix <- table(test$price_cat, predictions)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
# 분류 트리 모델 생성
c50_model <- C5.0(price_cat ~ ., data = train)
# test 데이터에 대해 예측
predictions <- predict(c50_model, newdata = test)
confusion_matrix <- table(test$price_cat, predictions)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
for (count in 1:33) {
boosted_model <- C5.0(price_cat ~ ., data = train, trials = count)
predictions <- predict(boosted_model, newdata = test)
confusion_matrix <- table(test$price_cat, predictions)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Trials의 갯수:", count, "--> Accuracy with Boosting:", accuracy, "\n")
}
library(dplyr)
df = read.csv('data/INTC.csv')
# 데이터 구조 확인
str(df)
# 컬럼 이름 확인
colnames(df)
# 요약 통계
summary(df)
# 결측값 확인
sum(is.na(df))           # 전체 결측값 개수
# 처음 몇 개의 행 확인
head(df)
# 마지막 몇 개의 행 확인
tail(df)
install.packages("caret")
library(caret)
preproc_z <- preProcess(df[, numeric_cols], method = c("center", "scale"))
preproc <- preProcess(df, method = c("range"))
df_normalized <- predict(preproc, df)
# 결과 확인
head(df_normalized)
set.seed(2024)
n <- nrow(df_normalized)
train_indices <- sample(seq_len(n), size = round(0.75 * n)) # 75%는 train
train <- df_normalized[train_indices, ]                                # train 데이터
test <- df_normalized[-train_indices, ]                                # test 데이터
dim(train)
dim(test)
##### 4. TomorrowOpen을 예측하는 neuralnet 모델 훈련
head(train)
install.packages("neuralnet")
library(neuralnet)
# 시드 고정
set.seed(1313)
# formula로 예측할 변수와 입력 변수를 지정
formula <- TomorrowOpen ~ Open + High + Low + Close + Adj.Close + Volume
nn_model <- neuralnet(
formula,
data = train_numeric,
hidden = c(1),         # 은닉층 1개
linear.output = TRUE,  # 연속형 변수 예측
stepmax = 1e6          # 최대 반복 수 설정 (필요 시 조정)
)
nn_model <- neuralnet(
formula,
data = train,
hidden = c(1),         # 은닉층 1개
linear.output = TRUE,  # 연속형 변수 예측
stepmax = 1e6          # 최대 반복 수 설정 (필요 시 조정)
)
print(nn_model)
plot(nn_model)  # 신경망 시각화
# c. 예측 수행
nn_predictions <- compute(nn_model, test[, c("Open", "High", "Low", "Close", "Adj.Close", "Volume")])
# 5. 결과 확인
test$Predicted_TomorrowOpen <- nn_predictions$net.result
# 결과 비교
head(test[, c("TomorrowOpen", "Predicted_TomorrowOpen")])
mse <- mean((test$TomorrowOpen - test$Predicted_TomorrowOpen)^2)
c
mse <- mean((test$TomorrowOpen - test$Predicted_TomorrowOpen)^2)
cat("Mean Squared Error (MSE):", mse, "\n")
r2 <- 1 - sum((test$TomorrowOpen - test$Predicted_TomorrowOpen)^2) /
sum((test$TomorrowOpen - mean(test$TomorrowOpen))^2)
cat("R-squared (R²):", r2, "\n")
nn_model <- neuralnet(
formula,
data = train,
hidden = c(1),         # 은닉층 1개
linear.output = TRUE,  # 연속형 변수 예측
stepmax = 1e6          # 최대 반복 수 설정 (필요 시 조정)
)
# c. 예측 수행
nn_predictions <- compute(nn_model, test[, c("Open", "High", "Low", "Close", "Adj.Close", "Volume")])
test$Predicted_TomorrowOpen <- nn_predictions$net.result
head(test[, c("TomorrowOpen", "Predicted_TomorrowOpen")])
mse <- mean((test$TomorrowOpen - test$Predicted_TomorrowOpen)^2)
cat("Mean Squared Error (MSE):", mse, "\n")
r2 <- 1 - sum((test$TomorrowOpen - test$Predicted_TomorrowOpen)^2) /
sum((test$TomorrowOpen - mean(test$TomorrowOpen))^2)
cat("R-squared (R²):", r2, "\n")
df <- read.csv('data/breast-cancer-wisconsin-data.csv')
head(df)
# 데이터 구조 확인
str(df)
# 결측값 확인
sum(is.na(df))           # 전체 결측값 개수
dim(df)
colSums(is.na(df))       # 각 열의 결측값 개수
# 결측값이 있는 마지막 컬럼 X를 제거
df <- df[, !names(df) %in% "X"]
dim(df)
# 데이터 분석에 필요하지 않은 첫번째 컬럼 id를 제거
df <- df[, !names(df) %in% "id"]
features <- df[, !names(df) %in% "diagnosis"]   # diagnosis를 제외한 나머지 열 추출
preproc <- preProcess(features, method = c("center", "scale"))  # 표준화 (Z-score normalization)
features_standardized <- predict(preproc, features)
# 표준화된 데이터 확인
head(features_standardized)
df_standardized <- cbind(diagnosis = df$diagnosis, features_standardized)
# 결과 확인
head(df_standardized)
set.seed(2024)
n <- nrow(df_standardized)
train_indices <- sample(seq_len(n), size = round(0.75 * n)) # 75%는 train
train <- df_standardized[train_indices, ]                                # train 데이터
test <- df_standardized[-train_indices, ]                                # test 데이터
dim(train)
dim(test)
install.packages("e1071")
library(e1071)
features <- df[, !names(df) %in% "diagnosis"]   # diagnosis를 제외한 나머지 열 추출
preproc <- preProcess(features, method = c("center", "scale"))  # 표준화 (Z-score normalization)
##### 1. 데이터 로드 후, 구조 확인 및 데이터 파악
df <- read.csv('data/breast-cancer-wisconsin-data.csv')
# 결측값이 있는 마지막 컬럼 X를 제거
df <- df[, !names(df) %in% "X"]
# 데이터 분석에 필요하지 않은 첫번째 컬럼 id를 제거
df <- df[, !names(df) %in% "id"]
features <- df[, !names(df) %in% "diagnosis"]   # diagnosis를 제외한 나머지 열 추출
preproc <- preProcess(features, method = c("center", "scale"))  # 표준화 (Z-score normalization)
##### 1. 데이터 로드 후, 구조 확인 및 데이터 파악
library(caret)
preproc <- preProcess(features, method = c("center", "scale"))  # 표준화 (Z-score normalization)
features_standardized <- predict(preproc, features)
# 표준화된 데이터 확인
head(features_standardized)
df$diagnosis <- as.factor(df$diagnosis)
df_standardized <- cbind(diagnosis = df$diagnosis, features_standardized)
set.seed(2024)
n <- nrow(df_standardized)
train_indices <- sample(seq_len(n), size = round(0.75 * n)) # 75%는 train
train <- df_standardized[train_indices, ]                                # train 데이터
test <- df_standardized[-train_indices, ]                                # test 데이터
dim(train)
dim(test)
svm_model <- svm(diagnosis ~ ., data = train, kernel = "radial")
library(e1071)
# SVM 모델 생성
svm_model <- svm(diagnosis ~ ., data = train, kernel = "radial")
# 모델 요약
summary(svm_model)
##### 3. test 데이터에 대한 예측 및 평가 진행
# 테스트 데이터 예측
svm_predictions <- predict(svm_model, test)
# 혼동 행렬 계산
confusion_matrix <- table(Predicted = svm_predictions, Actual = test$diagnosis)
print(confusion_matrix)
# 정확도 계산
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
teens <- read.csv('snsdata1.csv')
teens <- read.csv('data/snsdata1.csv')
head(teens)
# 결측값 확인
sum(is.na(teens))
dim(teens)
head(interests)
interests <- teens[, 13:37]
head(interests)
interests_z <- as.data.frame(scale(interests))
head(interests_z)
# k-means 클러스터링 수행
kmeans_result <- kmeans(interests_z, centers = 4, nstart = 25)
# k-means 클러스터링 수행
kmeans_result <- kmeans(interests_z, centers = 4, nstart = 25, iter.max = 100)
# 군집 결과를 interests_z에 추가
interests_z$cluster <- as.factor(kmeans_result$cluster)
head(interests_z)
interests_z$cluster <- as.factor(kmeans_result$cluster)
head(interests_z)
tail(head(clusters, 105), 5)
##### 4. 본래 데이터프레임에 군집 ID(cluster ID)를 적용하여 clusters 생성
#####    생성후 101행부터 105행까지 "cluster","gender", "friends", "drunk", "drugs" 데이터 추출
clusters <- cbind(cluster = interests_z$cluster, teens)
tail(head(clusters, 105), 5)
# 필요한 컬럼만 추출
tail(head(clusters["cluster","gender", "friends", "drunk", "drugs"], 105), 5)
# 필요한 컬럼만 101행부터 105행까지 추출
library(dplyr)
subset_clusters <- clusters %>%
select(cluster, gender, friends, drunk, drugs)
tail(head(subset_clusters, 105), 5)
